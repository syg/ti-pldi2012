\section{Evaluation}
\label{sec:evaluation}

We evaluate the effectiveness of our analysis in two ways.
In \Section\ref{sec:benchmarks} we compare the performance on major JavaScript benchmarks
of a single compiler with and without use of analyzed type information.
In \Section\ref{sec:websites} we examine the behavior of the analysis on a selection of
JavaScript-heavy websites to gauge the effectiveness of the analysis in practice.

\subsection{Benchmark Performance}
\label{sec:benchmarks}


As described in \Section\ref{sec:implementation}, we have integrated our analysis into
the JaegerMonkey JIT compiler used in Firefox.
We compare performance of the compiler used both without the analysis (JM)
and with the analysis (JM+TI).
JM+TI adds several major optimizations to JM,
and requires additional compilations due to dynamic type changes
(\Section\ref{sec:recompilation}).
Figure~\ref{fig:sunspider} shows the effect of these changes on the popular
SunSpider\footnote{\url{http://www.webkit.org/perf/sunspider/sunspider.html}} JavaScript benchmark.

The compilation sections of Figure~\ref{fig:sunspider} show the total amount of time
spent compiling and the total number of script compilations for both versions of
the compiler.
For JM+TI, compilation time also includes time spent generating and solving
type constraints, which is small: 4ms for the entire benchmark.
JM performs 146 compilations, while JM+TI performs 224, an increase of 78.
The total compilation time for JM+TI is 2.52 times that of JM, an increase
of 32ms, due a combination of recompilations, type analysis and the extra
complexity of the added optimizations.

Despite the significant extra compilation cost, the type-based optimizations
performed by JM+TI quickly pay for themselves. The $\times$1 and
$\times$20 sections
of Figure~\ref{fig:sunspider} show the running times of the two versions of the
compiler and generated code on the benchmark run once and modified
to run twenty times, respectively.
In the single run case JM+TI improves over JM by a factor of 1.06.
One run of SunSpider completes in less than 250ms, which makes it
difficult to get an optimization to pay for itself on this benchmark.
JavaScript-heavy webpages are typically viewed for longer than
1/4 of a second, and longer execution times better show the effect
of type based optimizations.
When run twenty times, the speedup given by JM+TI increases to a factor of 1.27.

Figures~\ref{fig:v8bench} and~\ref{fig:kraken} compare the performance of JM and JM+TI
on two other popular benchmarks, the V8\footnote{\url{http://v8.googlecode.com/svn/data/benchmarks/v6/run.html}}
and Kraken\footnote{\url{http://krakenbenchmark.mozilla.org}} suites.
These suites run for several seconds each, far longer than SunSpider,
and show a larger speedup.
V8 scores (which are given as a rate, rather than a raw time; larger is better) improve by a factor of 1.50,
and Kraken scores improve by a factor of 2.69.

Across the benchmarks, not all tests improved equally, and some regressed compared to
the engine's performance without the analysis.
These include the date-format-xparb and string-tagcloud tests in SunSpider,
and the RayTrace and RegExp tests in the V8.
These are tests which spend little time in JIT code, and perform many side
effects in VM code itself.
Changes to objects which happen in the VM due to, e.g., the behavior of
builtin functions, must be tracked to ensure the correctness of type
information for the heap.
We are working to reduce the overhead incurred by such side effects.

\subsubsection{Performance Cost of Barriers}
\label{sec:barrier_cost}

The cost of using type barriers is of crucial importance for two reasons.
First, if barriers are very expensive then the effectiveness of the compiler
on websites which require many barriers (\Section\ref{sec:barriers})
is greatly reduced.
Second, if barriers are very cheap then the time and memory spent
tracking the types of heap values would be unnecessary.

To estimate this cost, we modified the compiler to artificially introduce
barriers at every indexed and property access, as if the types of all values
in the heap were unknown.
For benchmarks, this is a great increase above the baseline barrier
frequency (\Section\ref{sec:barriers}).
Figure~\ref{fig:benchmarks100} gives times for the modified compiler on the
tracked benchmarks.
On a single run of SunSpider, performance was even with the JM
compiler.
In all other cases, performance was significantly better than the JM
compiler and significantly worse than the JM+TI compiler.

This indicates that while the compiler will still be able to effectively
optimize code in cases where types of heap values are not well known,
accurately inferring such types and minimizing the barrier count is important
for maximizing performance.

\begin{figure}
\centering
\begin{tabular}{lrrrr}
\toprule
Test & JM & JM+TI & Ratio \\
\midrule
Richards & 4497 & 7152 & 1.59 \\
DeltaBlue & 3250 & 9087 & 2.80 \\
Crypto & 5205 & 13376 & 2.57 \\
RayTrace & 3733 & 3217 & 0.86 \\
EarleyBoyer & 4546 & 6291 & 1.38 \\
RegExp & 1547 & 1316 & 0.85 \\
Splay & 4775 & 7049 & 1.48 \\
\midrule
Total & 3702 & 5555 & 1.50 \\
\bottomrule
\end{tabular}
\nocaptionrule \caption{V8 (version 6) Benchmark Scores (higher is better)}
\label{fig:v8bench}
\end{figure}

\begin{figure}
\centering
\begin{tabular}{lrrr}
\toprule
Test & JM (ms) & JM+TI (ms) & Ratio \\
\midrule
ai-astar & 889.4 & 137.8 & 0.15 \\
audio-beat-detection & 641.0 & 374.8 & 0.58 \\
audio-dft & 627.8 & 352.6 & 0.56 \\
audio-fft & 494.0 & 229.8 & 0.47 \\
audio-oscillator & 518.0 & 221.2 & 0.43 \\
imaging-gaussian-blur & 4351.4 & 730.0 & 0.17 \\
imaging-darkroom & 699.6 & 586.8 & 0.84 \\
imaging-desaturate & 821.2 & 209.2 & 0.25 \\
json-parse-financial & 116.6 & 119.2 & 1.02 \\
json-stringify-tinderbox & 80.0 & 78.8 & 0.99 \\
crypto-aes & 201.6 & 158.0 & 0.78 \\
crypto-ccm & 127.8 & 133.6 & 1.05 \\
crypto-pbkdf2 & 454.8 & 350.2 & 0.77 \\
crypto-sha256-iterative & 153.2 & 106.2 & 0.69 \\
\midrule
Total & 10176.4 & 3778.2 & 0.37 \\
\bottomrule
\end{tabular}
\nocaptionrule \caption{Kraken-1.1 Benchmark Results}
\label{fig:kraken}
\end{figure}

\begin{figure}
\centering
\begin{tabular}{lrrr}
\toprule
Suite & Time/Score & vs. JM & vs. JM+TI \\
\midrule
Sunspider-0.9.1 $\times$1  & 262.2  & 1.00 & 1.06 \\
Sunspider-0.9.1 $\times$20 & 4044.3 & 0.86  & 1.09 \\
Kraken-1.1          & 7948.6 & 0.78  & 2.10 \\
V8 (version 6)      & 4317   & 1.17 & 0.78 \\
\bottomrule
\end{tabular}
\nocaptionrule \caption{Benchmark Results with 100\% barriers}
\label{fig:benchmarks100}
\end{figure}

\begin{figure*}
\centering
\begin{tabular}{lrrrrrrrrrrrrrrr}
\toprule
& \multicolumn{3}{c}{Inferred Precision (\%)} &
& \multicolumn{4}{c}{Arithmetic (\%)}
& \multicolumn{4}{c}{Indices (\%)} \\

\cmidrule(r){2-4}
\cmidrule(r){6-9}
\cmidrule{10-13}

Test
& Mono & Di & Poly & Barrier (\%)
& Int & Double & Other & Unknown
& Int & Double & Other & Unknown \\
\midrule
gmail          & 78 & 5  & 17 & 47 & 62 & 9  & 7  & 21 & 44 & 0 & 47 & 8 \\
googlemaps     & 81 & 7  & 12 & 36 & 66 & 26 & 3  & 5  & 60 & 6 & 30 & 4 \\
facebook       & 73 & 11 & 16 & 42 & 43 & 0 & 40 & 16 & 62 & 0 & 32 & 6 \\
flickr         & 71 & 19 & 10 & 74 & 61 & 1 & 30 & 8 & 27 & 0 & 70 & 3 \\
grooveshark    & 64 & 15 & 21 & 63 & 65 & 1 & 13 & 21 & 28 & 0 & 56 & 16 \\
meebo          & 78 & 11 & 10 & 35 & 66 & 9 & 18 & 8 & 17 & 0 & 34 & 49 \\
reddit         & 71 & 7 & 22 & 51 & 64 & 0 & 29 & 7 & 22 & 0 & 71 & 7 \\
youtube        & 83 & 11 & 6 & 38 & 50 & 27 & 19 & 4 & 33 & 0 & 38 & 29 \\
280slides      & 79 & 3 & 19 & 64 & 48 & 51 & 1 & 0 & 6 & 0 & 91 & 2 \\
membench50     & 76 & 11 & 13 & 49 & 65 & 7  & 18 & 10 & 44 & 0 & 47 & 10 \\
\midrule
sunspider      & 99 & 0  & 1  & 7  & 72 & 21 & 7  & 0  & 95 & 0 & 4  & 1  \\
v8bench        & 86 & 7  & 7  & 26 & 98 & 1  & 0  & 0  & 100 & 0 & 0 & 0  \\
kraken         & 100 & 0 & 0  & 3  & 61 & 37 & 2  & 0  & 100 & 0 & 0 & 0  \\
\midrule
angrybirds     & 97 & 2 & 1 & 93 & 22 & 78 & 0 & 0 & 88 & 8 & 0 & 5 \\
gameboy        & 88 & 0 & 12 & 16 & 54 & 36 & 3 & 7 & 88 & 0 & 0 & 12 \\
bullet         & 84 & 0 & 16 & 92 & 54 & 38 & 0 & 7 & 79 & 20 & 0 & 1 \\
lights         & 97 & 1 & 2 & 15 & 34 & 66 & 0 & 1 & 95 & 0 & 4 & 1 \\
FOTN           & 98 & 1 & 1 & 20 & 39 & 61 & 0 & 0 & 96 & 0 & 3 & 0 \\
monalisa       & 99 & 1 & 0 & 4 & 94 & 3 & 2 & 0 & 100 & 0 & 0 & 0 \\
ztype          & 91 & 1 & 9 & 52 & 43 & 41 & 8 & 8 & 79 & 9 & 12 & 0 \\
\midrule
Average        & 84.7 & 5.7 & 9.8 & 41.4 & 58.1 & 25.7 & 10.0 & 6.2 & 63.2 & 1.7 & 27.0 & 7.7 \\
\bottomrule
\end{tabular}
\nocaptionrule \caption{Website Type Profiling Results}
\label{fig:polymorphism}
\end{figure*}

\subsection{Website Performance}
\label{sec:websites}

In this section we measure the precision of the analysis
on a variety of websites.
The impact of compiler optimizations is difficult to accurately
measure on websites due to confounding issues like differences
in network latency and other browser effects.
Since analysis precision directly ties into the quality of
generated code, it makes a good surrogate for optimization effectiveness.

We modified Firefox to track several precision metrics,
all of which operate at the granularity of individual operations.
%These metrics are generally useful for debugging performance faults,
%and will be released with a future version of Firefox.
A brief description of the websites used is included below.

\begin{itemize}

\item Nine popular websites which use JavaScript extensively.
Each site was used for several minutes, exercising various features.

\item The membench50 suite\footnote{\url{http://gregor-wagner.com/tmp/mem50}},
a memory testing framework
which loads the front pages of 50 popular websites.

\item The three benchmark suites described in \Section\ref{sec:benchmarks}.

\item Seven games and demos which are bound on JavaScript performance.
Each was used for several minutes or, in the case of non-interactive
demos, viewed to completion.

\end{itemize}

A full description of the tested websites and methodology used for each
is available in the appendix of the full version of the paper.

When developing the analysis and compiler we tuned behavior for the three
covered benchmark suites, as well as various websites.
Besides the benchmarks, no tuning work has been done for any of the
websites described here.

We address several questions related to analysis precision,
listed by section below. The answers to these sometimes differ significantly
across the different categories of websites.

\begin{enumerate}
\setlength{\itemindent}{2.5em}

\item[\Section\ref{sec:access_polymorphism}] How polymorphic are values read at access sites?

\item[\Section\ref{sec:barriers}] How often are type barriers required?

\item[\Section\ref{sec:operations}] How polymorphic are performed operations?

\item[\Section\ref{sec:access_objects}] How polymorphic are the objects used at access sites?

\item[\Section\ref{sec:without_barriers}] How important are type barriers for precision?

\end{enumerate}



\subsubsection{Access Site Polymorphism}
\label{sec:access_polymorphism}

The degree of polymorphism used in practice is of utmost importance
for our analysis.
The analysis is sound and will always compute a lower bound on the possible
types that can appear at the various points in a program,
so the precision of the generated type information is limited for
access sites and operations which are polymorphic in practice.
We draw the following distinction for the level of precision obtained:

\begin{description}

\item[Monomorphic] Sites that have only ever produced a single kind of value.
Two values are of the same kind if they are either primitives of the same
type or both objects with possibly different
object types.
Access sites containing objects of multiple types can often be optimized
just as well as sites containing objects of a single type, as long as
all the observed object types share common attributes (\Section\ref{sec:access_objects}).

\item[Dimorphic] Sites that have produced either strings or objects (but not both),
and also at most one of the \code{undefined}, \code{null}, or a boolean value.
Even though multiple kinds are possible at such sites, an untyped
representation can still be used,
as a single test on the unboxed form will determine the type.
The untyped representation of objects and strings are pointers,
whereas \code{undefined}, \code{null}, and booleans are either $0$ or $1$.

\item[Polymorphic] Sites that have produced values of multiple kinds.
Compiled code must use a typed representation which keeps track of
the value's kind.

\end{description}

The inferred precision section of Figure~\ref{fig:polymorphism} shows the fractions
of dynamic indexed element and property reads which were at a site inferred
as producing
monomorphic, dimorphic, or polymorphic sets of values.
All these sites have type barriers on them, so the set of inferred types
is equivalent to the set of observed types.

The category used for a dynamic access is determined from the types
inferred at the time of the access.
Since the types inferred for an access site can grow as a program executes,
dynamic accesses at the same site can contribute to different
columns over time.

Averaged across pages, 84.7\% of reads were at monomorphic
sites, and 90.2\% were at monomorphic or dimorphic sites.
The latter figure is 85.4\% for websites, 97.3\% for benchmarks,
and 94.3\% for games and demos; websites are more polymorphic than games
and demos, but by and large behave in a monomorphic fashion.

\subsubsection{Barrier Frequency}
\label{sec:barriers}

Examining the frequency with which type barriers are required
gives insight to the precision of the model of the heap constructed by
the analysis.

The {\it Barrier} column of Figure~\ref{fig:polymorphism} shows the frequencies of
indexed and property accesses on sampled pages which required a barrier.
Averaged across pages, barriers were required on 41.4\% of such accesses.
There is a large disparity between websites and other pages.
Websites were fairly homogenous, requiring barriers on between 35\%
and 74\% of accesses (averaging 50\%), while benchmarks,
games and demos were generally
much lower, averaging 17.9\% except for two outliers above 90\%.

The larger proportion of barriers required for websites indicates that
heap layouts and types tend to be more complicated for websites than for
games and demos.
Still, the presence of the type barriers themselves means that we
detect as monomorphic the very large proportion of access sites which are,
with only a small amount of barrier checking overhead incurred by the
more complicated heaps.

The two outliers requiring a very high proportion of barriers do most of
their accesses at a small number of sites; the involved objects have
multiple types assigned to their properties, which leads to barriers being
required.
Per \Section\ref{sec:barrier_cost}, such sites will still see significant
performance improvements but will perform worse than if the barriers were
not in place.
We are building tools to identify hot spots and performance
faults in order to help developers more easily optimize their code.

\subsubsection{Operation Precision}
\label{sec:operations}

The arithmetic and indices sections of Figure~\ref{fig:polymorphism} show the frequency
of inferred types for arithmetic operations and the index operand of
indexed accesses, respectively.
These are operations for which precise type information is crucial
for efficient compilation, and give a sense of the precision of type
information for operations which do not have associated type barriers.

In the arithmetic section, the {\it Int}, {\it Double}, {\it Other},
and {\it Unknown} columns indicate,
respectively,
operations on known integers which give an integer result,
operations on integers or doubles which give a double result,
operations on any other type of known value,
and operations where at least one of the operand types is unknown.
Overall, precise types were found for 93.8\% of arithmetic operations,
including 90.2\% of operations performed by websites.
Comparing websites with other pages, websites tend to do far more
arithmetic on non-numeric values --- 27.8\% vs. 0.5\% ---
and considerably less arithmetic on doubles --- 13.1\% vs. 46.1\%.

In the indices section, the {\it Int}, {\it Double}, {\it Other}, and
{\it Unknown} columns indicate, respectively, that the type of the index, i.e.,
the type of \code{i} in an expression such as \code{a[i]}, is known
to be an integer, a double, any other known type, or unknown. Websites tend to
have more unknown index types than both benchmarks and games.

\begin{figure}
\centering
\begin{tabular}{lrrrrrr}
\toprule
     & \multicolumn{3}{c}{Indexed Acc. (\%)}
     & \multicolumn{3}{c}{Property Acc. (\%)} \\
\cmidrule(r){2-4}
\cmidrule{5-7}
Test & Packed & Array & Uk
     & Def & PIC & Uk \\
\midrule
gmail          & 90 & 4 & 5 & 31 & 57 & 12 \\
googlemaps     & 92 & 1 & 7 & 18 & 77 & 5 \\
facebook       & 16 & 68 & 16 & 41 & 53 & 6 \\
flickr         & 27 & 0 & 73 & 33 & 53 & 14 \\
grooveshark    & 90 & 2 & 8 & 20 & 66 & 14 \\
meebo          & 57 & 0 & 43 & 40 & 57 & 3 \\
reddit         & 97 & 0 & 3 & 45 & 51 & 4 \\
youtube        & 100 & 0 & 0 & 32 & 49 & 19 \\
280slides      & 88 & 12 & 0 & 23 & 56 & 21 \\
membench50     & 80 & 4 & 16 & 35 & 58 & 6 \\
\midrule
sunspider      & 93 & 6 & 1 & 81 & 19 & 0 \\
v8bench        & 7 & 93 & 0 & 64 & 36 & 0 \\
kraken         & 99 & 0 & 0 & 96 & 4 & 0 \\
\midrule
angrybirds     & 90 & 0 & 10 & 22 & 76 & 2 \\
gameboy        & 98 & 0 & 2 & 6 & 94 & 0 \\
bullet         & 4 & 96 & 0 & 32 & 65 & 3 \\
lights         & 97 & 3 & 1 & 21 & 78 & 1 \\
FOTN           & 91 & 6 & 3 & 46 & 54 & 0 \\
monalisa       & 87 & 0 & 13 & 78 & 22 & 0 \\
ztype          & 100 & 0 & 0 & 23 & 76 & 0 \\
\midrule
Average        & 75.2 & 14.8 & 10.1 & 39.4 & 55.1 & 5.5 \\
\bottomrule
\end{tabular}
\nocaptionrule \caption{Indexed/Property Access Precision}
\label{fig:access_objects}
\end{figure}

\begin{figure}[ht]
\centering
\begin{tabular}{lrrrr}
\toprule
     & \multicolumn{2}{c}{Precision}
     & \multicolumn{2}{c}{Arithmetic} \\
\cmidrule(r){2-3}
\cmidrule{4-5}
Test & Poly (\%) & Ratio & Unknown (\%) & Ratio \\
\midrule
gmail          & 46 & 2.7 & 32 & 1.5 \\
googlemaps     & 38 & 3.2 & 23 & 4.6 \\
facebook       & 48 & 3.0 & 20 & 1.3 \\
flickr         & 61 & 6.1 & 39 & 4.9 \\
grooveshark    & 58 & 2.8 & 30 & 1.4 \\
meebo          & 36 & 3.6 & 28 & 3.5 \\
reddit         & 37 & 1.7 & 13 & 1.9 \\
youtube        & 40 & 6.7 & 28 & 7.0 \\
280slides      & 76 & 4.0 & 93 & --- \\
membench50     & 47 & 3.6 & 29 & 2.9 \\
\midrule
sunspider      & 5 & --- & 6 & --- \\
v8bench        & 18 & 2.6 & 1 & --- \\
kraken         & 2 & --- & 2 & --- \\
\midrule
angrybirds     & 90 & --- & 93 & --- \\
gameboy        & 15 & 1.3 & 7 & 1.0 \\
bullet         & 62 & 3.9 & 79 & 11.3 \\
lights         & 37 & --- & 63 & --- \\
FOTN           & 28 & --- & 57 & --- \\
monalisa       & 44 & --- & 41 & --- \\
ztype          & 54 & 6.0 & 63 & 7.9 \\
\midrule
Average        & 42.1 & 4.3 & 37.4 & 6.0 \\
\bottomrule
\end{tabular}
\nocaptionrule \caption{Type Profiles Without Barriers}
\label{fig:without_barriers}
\end{figure}

\subsubsection{Access Site Precision}
\label{sec:access_objects}

Efficiently compiling indexed element and property accesses requires
knowledge of the kind of object being accessed.
This information is more specific than the monomorphic/polymorphic
distinction drawn in \Section\ref{sec:access_polymorphism}.
Figure~\ref{fig:access_objects} shows the fractions of indexed accesses on arrays
and of all property accesses which were optimized based on static knowledge.

In the indexed access section, the {\it Packed} column shows the fraction
of operations known to be on packed arrays (\Section\ref{sec:supplemental-analyses}),
while the {\it Array} column shows the fraction known to be on arrays not
known to be packed.
Indexed operations behave differently on arrays vs. other objects,
and avoiding dynamic array checks achieves some speedup.
The {\it Uk} column is the fraction of dynamic accesses on arrays which
are not statically known to be on arrays.

Static detection of array operations is very good on all kinds of sites,
with an average of 75.2\% of accesses on known packed arrays and
an additional 14.8\% on known but possibly not packed arrays.
A few outlier websites are responsible for the great majority of
accesses in the latter category.
For example, the V8 Crypto benchmark contains almost all of the benchmark's
array accesses, and the arrays used are not known to be packed
due to the top down order in which they are initialized.
Still, speed improvements on this benchmark are very large.

In the property access section of Figure~\ref{fig:access_objects},
the {\it Def} column shows the fraction
of operations which were statically resolved as definite properties
(\Section\ref{sec:supplemental-analyses}), while the {\it PIC} column shows the fraction which
were not resolved statically but were matched using a fallback mechanism,
polymorphic inline caches \cite{Holzle91}.
The {\it Uk} column is the fraction of operations which were not resolved
either statically or with a PIC and required a call into the VM;
this includes accesses where objects
with many different layouts are used, and accesses on rare kinds of
properties such as those with scripted getters or setters.

The {\it Def} column gives a measurement of how many times during execution dynamic checks were avoided. Since our analysis is hybrid, we cannot (nor does it make sense to) measure how many dynamic checks are statically removed, as a site whose dynamic checks have been removed may have them re-added due to invalidation of analysis results.

An average of 39.4\% of property accesses were resolved as definite properties,
with a much higher average proportion on benchmarks of 80.3\%.
The remainder were mostly handled by PICs, with only 5.5\% of
accesses requiring a VM call.
Together, these suggest that objects on websites are by and large
constructed in a consistent fashion, but that
our detection of definite properties needs
to be more robust on object construction patterns seen on websites but
not on benchmarks.

\subsubsection{Precision Without Barriers}
\label{sec:without_barriers}

To test the practical effect of using type barriers to improve precision,
we repeated the above website tests using a build of Firefox where
subset constraints were used in place of barrier constraints,
and type barriers were not used at all (semantic triggers were still used).
Some of the numbers from these runs are shown in Figure~\ref{fig:without_barriers}.

The precision section shows the fraction of indexed and property accesses which
were inferred as polymorphic, and the arithmetic section shows the fraction
of arithmetic operations where at least one operand type was unknown.
Both sections show the ratio of the given fraction to the comparable fraction
with type barriers enabled,
with entries struck out when the comparable fraction is near zero.
Overall, with type barriers disabled 42.1\% of accesses are polymorphic and 37.4\%
of arithmetic operations have operands of unknown type; precision is far worse
than with type barriers.

Benchmarks are affected much less than other kinds of sites,
which makes it difficult to measure the practical performance impact 
of removing barriers.
These benchmarks use polymorphic structures much less
than the web at large.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
