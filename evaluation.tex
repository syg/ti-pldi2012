\begin{figure*}[ht]
\centering
\begin{tabular}{lr@{.}lrr@{.}lrr@{.}lr@{.}lr@{.}lr@{.}lr@{.}lr@{.}lr@{.}l}

\toprule

           & \multicolumn{3}{c}{JM}
           & \multicolumn{3}{c}{JM+TI}
           & \multicolumn{2}{c}{}
           & \multicolumn{6}{c}{$\times$1 Times (ms)}
           & \multicolumn{6}{c}{$\times$20 Times (ms)} \\

\cmidrule(r){2-4}
\cmidrule{5-7}
\cmidrule(r){10-15}
\cmidrule{16-21}

Test       & \multicolumn{2}{c}{Time (ms)} & \#
           & \multicolumn{2}{c}{Time (ms)} & \#
           & \multicolumn{2}{c}{Ratio}
           & \multicolumn{2}{c}{JM}
           & \multicolumn{2}{c}{JM+TI}
           & \multicolumn{2}{c}{Ratio}
           & \multicolumn{2}{c}{JM}
           & \multicolumn{2}{c}{JM+TI}
           & \multicolumn{2}{c}{Ratio} \\

\midrule

3d-cube                  & 2&68 & 15 & 8&21 & 24 & 3&06
    & 14&1 & 16&6 & 1&18 & 226&9 & 138&8 & 0&61 \\
3d-morph                 & 0&55 & 2   & 1&59 & 7  & 2&89 
    & 9&8  & 10&3 & 1&05 & 184&7 & 174&6 & 0&95 \\
3d-raytrace              & 2&25 & 19 & 6&04 & 22 & 2&68
    & 14&7 & 15&6 & 1&06 & 268&6 & 152&2 & 0&57 \\
access-binary-trees      & 0&63 & 4   & 1&03 & 7  & 1&63
    & 6&1  & 5&2 & 0&85   & 101&4 & 70&8  & 0&70 \\
access-fannkuch          & 0&65  & 1  & 2&43 & 4  & 3&76
    & 15&3 & 10&1 & 0&66  & 289&9 & 113&7 & 0&39 \\
access-nbody             & 1&01 & 5  & 1&49 & 5  & 1&47
    & 9&9  & 5&3 & 0&54   & 175&6 & 73&2  & 0&42 \\
access-nsieve            & 0&28 & 1   & 0&63 & 2   & 2&25
    & 6&9  & 4&5 & 0&65   & 143&1 & 90&7  & 0&63 \\
bitops-3bit-bits-in-byte & 0&28 & 2   & 0&58 & 3   & 2&07
    & 1&7  & 0&8 & 0&47    & 29&9 & 10&0   & 0&33 \\
bitops-bits-in-byte      & 0&29 & 2   & 0&54 & 3   & 1&86
    & 7&0  & 4&8 & 0&69   & 139&4 & 85&4  & 0&61 \\
bitops-bitwise-and       & 0&24 & 1   & 0&39 & 1   & 1&63
    & 6&1  & 3&1 & 0&51   & 125&2 & 63&7  & 0&51 \\
bitops-nsieve-bits       & 0&35 & 1   & 0&73 & 2   & 2&09
    & 6&0  & 3&6 & 0&60    & 116&1 & 63&9  & 0&55 \\
controlflow-recursive    & 0&38 & 3   & 0&65 & 6   & 1&71
    & 2&6  & 2&7 & 1&04  & 49&4  & 42&3  & 0&86 \\
crypto-aes               & 2&04 & 14 & 6&61 & 23 & 3&24
    & 9&3  & 10&9 & 1&17 & 162&6 & 107&7 & 0&66 \\
crypto-md5               & 1&81 & 9  & 3&42 & 13 & 1&89
    & 6&1  & 6&0 & 0&98   & 62&0  & 27&1  & 0&44 \\
crypto-sha1              & 0&88 & 7   & 2&46 & 11 & 2&80
    & 3&1  & 4&0 & 1&29  & 44&2  & 19&4  & 0&44 \\
date-format-tofte        & 0&93 & 21  & 2&27 & 24 & 2&44
    & 16&4 & 18&3 & 1&12 & 316&6 & 321&8 & 1&02 \\
date-format-xparb        & 0&88 & 7   & 1&26 & 6  & 1&43
    & 11&6 & 14&8 & 1&28 & 219&4 & 285&1 & 1&30 \\
math-cordic              & 0&45 & 3   & 0&94 & 5   & 2&09
    & 7&4  & 3&4 & 0&46   & 141&0 & 50&3  & 0&36 \\
math-partial-sums        & 0&47 & 1   & 1&03 & 3  & 2&19
    & 14&1 & 12&4 & 0&88  & 278&4 & 232&6 & 0&84 \\
math-spectral-norm       & 0&54 & 5   & 1&39 & 9  & 2&57
    & 5&0  & 3&4 & 0&68   & 92&6  & 51&2  & 0&55 \\
regexp-dna               & 0&00 & 0   & 0&00 & 0    & 0&00
    & 16&3 & 16&1 & 0&99  & 254&5 & 268&8 & 1&06 \\
string-base64            & 0&87 & 3   & 1&90 & 5   & 2&18
    & 7&8  & 6&5 & 0&83   & 151&9 & 103&6 & 0&68 \\
string-fasta             & 0&59 & 4   & 1&70 & 9   & 2&88
    & 10&0 & 7&3 & 0&73   & 124&0 & 93&4  & 0&75 \\
string-tagcloud          & 0&54 & 4   & 1&54 & 6  & 2&85
    & 21&0 & 24&3 & 1&16 & 372&4 & 433&4 & 1&17 \\
string-unpack-code       & 0&89 & 8   & 2&65 & 16 & 2&98
    & 24&4 & 26&7 & 1&09 & 417&6 & 442&5 & 1&06 \\
string-validate-input    & 0&58 & 4   & 1&65 & 8  & 2&84
    & 10&2 & 9&5 & 0&93   & 216&6 & 184&1 & 0&85 \\

\midrule

Total                  & 21&06 & 146 & 53&13 & 224 & 2&52
    & 261&9 & 246&4 & 0&94 & 4703&6 & 3700&3 & 0&79 \\

\bottomrule

\end{tabular}
\nocaptionrule \caption{SunSpider-0.9.1 Benchmark Results}
\label{fig:sunspider}
\end{figure*}

\begin{figure}
\centering
\begin{tabular}{lrrr@{.}l}
\toprule
Test & JM & JM+TI & \multicolumn{2}{c}{Ratio} \\
\midrule
Richards & 4497 & 7152 & 1&59 \\
DeltaBlue & 3250 & 9087 & 2&80 \\
Crypto & 5205 & 13376 & 2&57 \\
RayTrace & 3733 & 3217 & 0&86 \\
EarleyBoyer & 4546 & 6291 & 1&38 \\
RegExp & 1547 & 1316 & 0&85 \\
Splay & 4775 & 7049 & 1&48 \\
\midrule
Total & 3702 & 5555 & 1&50 \\
\bottomrule
\end{tabular}
\nocaptionrule \caption{V8 (version 6) Benchmark Results}
\label{fig:v8bench}
\end{figure}

\begin{figure}
\centering
\begin{tabular}{lr@{.}lr@{.}lr@{.}l}

\toprule

Test & \multicolumn{2}{c}{JM}
     & \multicolumn{2}{c}{JM+TI}
     & \multicolumn{2}{c}{Ratio} \\

\midrule

ai-astar & 889&4 & 137&8 & 0&15 \\
audio-beat-detection & 641&0 & 374&8 & 0&58 \\
audio-dft & 627&8 & 352&6 & 0&56 \\
audio-fft & 494&0 & 229&8 & 0&47 \\
audio-oscillator & 518&0 & 221&2 & 0&43 \\
imaging-gaussian-blur & 4351&4 & 730&0 & 0&17 \\
imaging-darkroom & 699&6 & 586&8 & 0&84 \\
imaging-desaturate & 821&2 & 209&2 & 0&25 \\
json-parse-financial & 116&6 & 119&2 & 1&02 \\
json-stringify-tinderbox & 80&0 & 78&8 & 0&99 \\
crypto-aes & 201&6 & 158&0 & 0&78 \\
crypto-ccm & 127&8 & 133&6 & 1&05 \\
crypto-pbkdf2 & 454&8 & 350&2 & 0&77 \\
crypto-sha256-iterative & 153&2 & 106&2 & 0&69 \\
\midrule
Total & 10176&4 & 3778&2 & 0&37 \\
\bottomrule
\end{tabular}
\nocaptionrule \caption{Kraken-1.1 Benchmark Results}
\label{fig:kraken}
\end{figure}


\section{Evaluation}
\label{sec:evaluation}

We evaluate the effectiveness of our analysis in two ways.
In \Section\ref{sec:benchmarks} we compare the performance on major JavaScript benchmarks
of a single compiler with and without use of analyzed type information.
In \Section\ref{sec:websites} we examine the behavior of the analysis on a selection of
websites which heavily use JavaScript to gauge analysis effectiveness in practice.

\subsection{Benchmark Performance}
\label{sec:benchmarks}

As described in \Section\ref{sec:implementation}, we have integrated our analysis into
the Jaegermonkey JIT compiler used in Firefox.
We compare performance of the compiler used both without the analysis (JM)
and with the analysis (JM+TI).
JM+TI adds several major optimizations to JM,
and requires additional compilations due to dynamic type changes
(\Section\ref{sec:recompilation}).
Figure~\ref{fig:sunspider} shows the effect of these changes on the popular
SunSpider JavaScript benchmark \cite{SunSpider}.

The JM and JM+TI sections of Figure~\ref{fig:sunspider} show the total amount of time
spent compiling and the total number of compilations for both versions of
the compiler.
For JM+TI, compilation time also includes time spent generating and solving
type constraints, which is small: 4ms for the entire benchmark.
JM performs 146 compilations, while JM+TI performs 224, an increase of 78.
The total compilation time for JM+TI is 2.52 times that of JM, an increase
of 32ms, due a combination of recompilations, type analysis and the extra
complexity of the added optimizations.

Despite the significant extra compilation cost, the type-based optimizations
performed by JM+TI quickly pay for themselves. The $\times$1 and
$\times$20 sections
of Figure~\ref{fig:sunspider} show the running times of the two versions of the
compiler on the benchmark run once and modified to run twenty times,
respectively.
In the single run case JM+TI is a 6.3\% improvement over JM.
One run of SunSpider completes in less than 250ms, which makes it
difficult to get an optimization to pay for itself on this benchmark.
JavaScript heavy webpages are typically viewed for longer than
$1/4$ of a second, and longer execution times better show the effect
of type based optimizations.
When run twenty times, the speedup given by JM+TI increases to 27.1\%.

Figures~\ref{fig:v8bench} and~\ref{fig:kraken} compare the performance of JM and JM+TI
on two other popular benchmarks, the V8 \cite{V8} and Kraken \cite{Kraken} suites.
These suites run for several seconds each, far longer than SunSpider,
and show a larger speedup.
V8 scores (which are given as a rate, rather than a raw time) improve by 50\%,
and Kraken scores improve by a factor of 2.69.

Across the benchmarks, not all tests improved equally, and some regressed over
the engine's performance without the analysis.
These include the date-format-xparb and string-tagcloud tests in SunSpider,
and the RayTrace and RegExp tests in the V8.
These are tests which spend little time in JIT code, and perform many side
effects in VM code itself.
Changes to objects which happen in the VM due to, e.g. the behavior of
builtin functions must be tracked to ensure the correctness of type
information for the heap.
We are working to reduce the overhead incurred by such side effects.

\begin{figure*}
\centering
\begin{tabular}{lrrrrrrrrrrrrrrr}
\toprule
& \multicolumn{3}{c}{Inferred Precision (\%)} &
& \multicolumn{4}{c}{Arithmetic (\%)}
& \multicolumn{4}{c}{Indexes (\%)} \\

\cmidrule(r){2-4}
\cmidrule(r){6-9}
\cmidrule{10-13}

Test
& Mono & Di & Poly & Barrier (\%)
& Int & Double & Other & Unknown
& Int & Double & Other & Unknown \\
\midrule
gmail          & 78 & 5  & 17 & 47 & 62 & 9  & 7  & 21 & 44 & 0 & 47 & 8 \\
googlemaps     & 81 & 7  & 12 & 36 & 66 & 26 & 3  & 5  & 60 & 6 & 30 & 4 \\
facebook       & 73 & 11 & 16 & 42 & 43 & 0 & 40 & 16 & 62 & 0 & 32 & 6 \\
flickr         & 71 & 19 & 10 & 74 & 61 & 1 & 30 & 8 & 27 & 0 & 70 & 3 \\
grooveshark    & 64 & 15 & 21 & 63 & 65 & 1 & 13 & 21 & 28 & 0 & 56 & 16 \\
meebo          & 78 & 11 & 10 & 35 & 66 & 9 & 18 & 8 & 17 & 0 & 34 & 49 \\
reddit         & 71 & 7 & 22 & 51 & 64 & 0 & 29 & 7 & 22 & 0 & 71 & 7 \\
youtube        & 83 & 11 & 6 & 38 & 50 & 27 & 19 & 4 & 33 & 0 & 38 & 29 \\
ztype          & 91 & 1 & 9 & 52 & 43 & 41 & 8 & 8 & 79 & 9 & 12 & 0 \\
280slides      & 79 & 3 & 19 & 64 & 48 & 51 & 1 & 0 & 6 & 0 & 91 & 2 \\
membench150    & 76 & 11 & 13 & 49 & 65 & 7  & 18 & 10 & 44 & 0 & 47 & 10 \\
\midrule
sunspider      & 99 & 0  & 1  & 7  & 72 & 21 & 7  & 0  & 95 & 0 & 4  & 1  \\
v8bench        & 86 & 7  & 7  & 26 & 98 & 1  & 0  & 0  & 100 & 0 & 0 & 0  \\
kraken         & 100 & 0 & 0  & 3  & 61 & 37 & 2  & 0  & 100 & 0 & 0 & 0  \\
\midrule
angrybirds     & 97 & 2 & 1 & 93 & 22 & 78 & 0 & 0 & 88 & 8 & 0 & 5 \\
gameboy        & 88 & 0 & 12 & 16 & 54 & 36 & 3 & 7 & 88 & 0 & 0 & 12 \\
bullet         & 84 & 0 & 16 & 92 & 54 & 38 & 0 & 7 & 79 & 20 & 0 & 1 \\
lights         & 97 & 1 & 2 & 15 & 34 & 66 & 0 & 1 & 95 & 0 & 4 & 1 \\
FOTN           & 98 & 1 & 1 & 20 & 39 & 61 & 0 & 0 & 96 & 0 & 3 & 0 \\
monalisa       & 99 & 1 & 0 & 4 & 94 & 3 & 2 & 0 & 100 & 0 & 0 & 0 \\
\midrule
Overall        & 84.7 & 5.7 & 9.8 & 41.4 & 58.1 & 25.7 & 10.0 & 6.2 & 63.2 & 1.7 & 27.0 & 7.7 \\
\bottomrule
\end{tabular}
\nocaptionrule \caption{Website Type Profiling Results}
\label{fig:polymorphism}
\end{figure*}

\subsection{Website Performance}
\label{sec:websites}

In this section we measure the precision of the analysis
on a variety of websites.
The impact of compiler optimizations is difficult to accurately
measure on websites due to confounding issues like differences
in network latency and other browser effects.
Since analysis precision directly ties into the quality of
generated code, it makes a good surrogate for optimization effectiveness.

We modified Firefox to track several precision metrics while running,
all of which operate at the granularity of individual operations.
%These metrics are generally useful for debugging performance faults,
%and will be released with a future version of Firefox.
A brief description of the websites used is below.
A full description of the tested websites and methodology used for each
is available in the appendix of the full version of the paper.

\begin{itemize}

\item Ten popular websites which use JavaScript extensively.
Each site was used for several minutes, exercising various features.

\item The membench150 suite, a memory testing framework
which loads the front pages of 150 popular websites \cite{MemBench}.

\item The three benchmark suites described in \Section\ref{sec:benchmarks}.

\item Six games and demos which are bound on JavaScript performance.
Each was used for several minutes or, in the case of non-interactive
demos, viewed to completion.

\end{itemize}

When developing the analysis and compiler we tuned behavior for the three
covered benchmark suites, as well as various websites.
Besides the benchmarks, no tuning work has been done for any of the
websites described here.

We address several questions related to analysis precision,
listed below. The answers to these sometimes differ significantly
across the different categories of websites.

\begin{enumerate}

\item How polymorphic are values read at access sites?  (\Section\ref{sec:access_polymorphism})

\item How often are type barriers required?  (\Section\ref{sec:barriers})

\item How polymorphic are performed operations?  (\Section\ref{sec:operations})

\item How polymorphic are the objects used at access sites?  (\Section\ref{sec:access_objects})

\item How important are type barriers?  (\Section\ref{sec:without_barriers})

\end{enumerate}



\subsubsection{Access Site Polymorphism}
\label{sec:access_polymorphism}

The degree of polymorphism used in practice is of utmost importance
for our analysis.
The analysis is sound and will always compute a lower bound on the possible
types that can appear at the various points in a program,
so the precision of the generated type information is limited for
access sites and operations which are polymorphic in practice.
We draw the following distinction:

\begin{description}

\item[Monomorphic] Sites that have only ever produced a single kind of value.
Two values are of the same kind if they are either primitives of the same
type or both objects with possibly different
object types.
Access sites containing objects of multiple types can often be optimized
just as well as sites containing objects of a single type, as long as
all the observed object types share common attributes (\Section\ref{sec:access_objects}).

\item[Dimorphic] Sites that have produced either strings or objects (but not both),
and also at most one of the \code{undefined}, \code{null} or a boolean value.
At such sites, even though multiple kinds are possible an untyped
representation can still be used,
as a single test on the unboxed form will determine the type.
The untyped representation of objects and strings are pointers,
whereas \code{undefined}, \code{null} and booleans are either $0$ or $1$.

\item[Polymorphic] Sites that have produced values of multiple kinds,
and compiled code must use a typed representation which keeps track of
the value's kind.

\end{description}

The inferred precision section of Figure~\ref{fig:polymorphism} shows the fractions
of dynamic indexed element and property reads which were at a site inferred
as producing
monomorphic, dimorphic, or polymorphic sets of values.
All these sites have type barriers on them, so the set of inferred types
is equivalent to the set of observed types.

The category used for a dynamic access is determined from the types
inferred at the time of the access.
Since the types inferred for an access site can grow as a program executes,
dynamic accesses at the same site can contribute to different
columns over time.

Averaged across pages, 84.7\% of reads were at monomorphic
sites, and 90.2\% were at monomorphic or dimorphic sites.
The latter figure is 85.9\% for websites, 97.3\% for benchmarks,
and 94.7\% for games and demos; websites are more polymorphic than games
and demos, but by and large behave in a monomorphic fashion.

\subsubsection{Barrier Frequency}
\label{sec:barriers}

Examining the frequency with which type barriers are required
gives insight to the precision of the model of the heap constructed by
the analysis.

The barrier section of Figure~\ref{fig:polymorphism} shows the frequencies of
indexed and property accesses on sampled pages which required a barrier.
Averaged across pages, barriers were required on 41.4\% of such accesses.
There is a large disparity between websites and other pages.
Websites were fairly homogenous, requiring barriers on between 35\%
and 74\% of accesses (averaging 50\%), while benchmarks,
games and demos were generally
much lower, averaging 13\% except for two outliers above 90\%.

The larger proportion of barriers required for websites indicates that
heap layouts and types tend to be more complicated for websites than for
games and demos.
Still, the presence of the type barriers themselves means that we
detect as monomorphic the very large proportion of access sites which are,
with only a small amount of barrier checking overhead incurred by the
more complicated heaps.

DISCUSS OUTLIERS

\subsubsection{Operation Precision}
\label{sec:operations}

The arithmetic and index sections of Figure~\ref{fig:polymorphism} show the frequency
of inferred types for arithmetic operations and the index operand of
indexed accesses, respectively.
These are operations for which precise type information is crucial
for efficient compilation, and give a sense of the precision of type
information for operations which do not have associated type barriers.

In the arithmetic section, the ``Integer'', ``Double'', ``Other'' and ``Unknown'' columns indicate,
respectively,
operations on known integers which give an integer result,
operations on integers or doubles which give a double result,
operations on any other type of known value,
and operations where at least one of the operand types is unknown.
Overall, precise types were found for 93.8\% of arithmetic operations,
including 90.2\% of operations performed by websites.
Comparing websites with other pages, websites tend to do far more
arithmetic on non-numeric values --- 16.8\% vs. 1.6\% ---
and considerably less arithmetic on doubles --- 14.8\% vs. 37.9\%.

\begin{figure}[ht]
\centering
\begin{tabular}{lrrrrrr}
\toprule
     & \multicolumn{3}{c}{Indexed Acc. (\%)}
     & \multicolumn{3}{c}{Property Acc. (\%)} \\
\cmidrule(r){2-4}
\cmidrule{5-7}
Test & Packed & Array & Uk
     & Def & PIC & Uk \\
\midrule
gmail          & 90 & 4 & 5 & 31 & 57 & 12 \\
googlemaps     & 92 & 1 & 7 & 18 & 77 & 5 \\
facebook       & 16 & 68 & 16 & 41 & 53 & 6 \\
flickr         & 27 & 0 & 73 & 33 & 53 & 14 \\
grooveshark    & 90 & 2 & 8 & 20 & 66 & 14 \\
meebo          & 57 & 0 & 43 & 40 & 57 & 3 \\
reddit         & 97 & 0 & 3 & 45 & 51 & 4 \\
youtube        & 100 & 0 & 0 & 32 & 49 & 19 \\
ztype          & 100 & 0 & 0 & 23 & 76 & 0 \\
280slides      & 88 & 12 & 0 & 23 & 56 & 21 \\
membench150    & 80 & 4 & 16 & 35 & 58 & 6 \\
\midrule
sunspider      & 93 & 6 & 1 & 81 & 19 & 0 \\
v8bench        & 7 & 93 & 0 & 64 & 36 & 0 \\
kraken         & 99 & 0 & 0 & 96 & 4 & 0 \\
\midrule
angrybirds     & 90 & 0 & 10 & 22 & 76 & 2 \\
gameboy        & 98 & 0 & 2 & 6 & 94 & 0 \\
bullet         & 4 & 96 & 0 & 32 & 65 & 3 \\
lights         & 97 & 3 & 1 & 21 & 78 & 1 \\
FOTN           & 91 & 6 & 3 & 46 & 54 & 0 \\
monalisa       & 87 & 0 & 13 & 78 & 22 & 0 \\
\midrule
Overall        & 75.2 & 14.8 & 10.1 & 39.4 & 55.1 & 5.5 \\
\bottomrule
\end{tabular}
\nocaptionrule \caption{Indexed/Property Access Precision}
\label{fig:access_objects}
\end{figure}

\begin{figure}[ht]
\centering
\begin{tabular}{lrrrr}
\toprule
     & \multicolumn{2}{c}{Precision}
     & \multicolumn{2}{c}{Arithmetic} \\
\cmidrule(r){2-3}
\cmidrule{4-5}
Test & Poly (\%) & Ratio & Unknown (\%) & Ratio \\
\midrule
gmail          & 46 & 2.7 & 32 & 1.5 \\
googlemaps     & 38 & 3.2 & 23 & 4.6 \\
facebook       & 48 & 3.0 & 20 & 1.3 \\
flickr         & 61 & 6.1 & 39 & 4.9 \\
grooveshark    & 58 & 2.8 & 30 & 1.4 \\
meebo          & 36 & 3.6 & 28 & 3.5 \\
reddit         & 37 & 1.7 & 13 & 1.9 \\
youtube        & 40 & 6.7 & 28 & 7.0 \\
ztype          & 54 & 6.0 & 63 & 7.9 \\
280slides      & 76 & 4.0 & 93 & n/a \\
membench150    & 47 & 3.6 & 29 & 2.9 \\
\midrule
sunspider      & 5 & n/a & 6 & n/a \\
v8bench        & 18 & 2.6 & 1 & n/a \\
kraken         & 2 & n/a & 2 & n/a \\
\midrule
angrybirds     & 90 & n/a & 93 & n/a \\
gameboy        & 15 & 1.3 & 7 & 1.0 \\
bullet         & 62 & 3.9 & 79 & 11.3 \\
lights         & 37 & n/a & 63 & n/a \\
FOTN           & 28 & n/a & 57 & n/a \\
monalisa       & 44 & n/a & 41 & n/a \\
\midrule
Overall        & 42.1 & 4.3 & 37.4 & 6.0 \\
\bottomrule
\end{tabular}
\nocaptionrule \caption{Type Profiles Without Barriers}
\label{fig:without_barriers}
\end{figure}

\subsubsection{Access Site Precision}
\label{sec:access_objects}

Efficiently compiling indexed element and property accesses requires
knowledge of the kind of object being accessed.
This information is more specific than the monomorphic/polymorphic
distinction drawn in \Section\ref{sec:access_polymorphism}.
Figure~\ref{fig:access_objects} shows the fractions of indexed accesses on arrays
and of all property accesses which were optimized based on static knowledge.

In the indexed access section, the ``Packed'' column shows the fraction
of operations known to be on packed arrays (\Section\ref{sec:supplemental-analyses}),
while the ``Array'' column shows the fraction known to be on arrays not
known to be packed.
Indexed operations behave differently on arrays vs. other objects,
and avoiding dynamic array checks achieves some speedup.
The ``Uk'' column is the fraction of dynamic accesses on arrays which
are not statically known to be on arrays.

Static detection of array operations is very good on all kinds of sites,
with an average of 75.2\% of accesses on known packed arrays and
an additional 14.8\% on known but possibly not packed arrays.
A few outlier websites are responsible for the great majority of
accesses in the latter category.
For example, the V8 Crypto benchmark contains almost all of the benchmark's
array accesses, and the arrays used are not known to be packed
due to the top down order they are initialized.
Still, speed improvements on this benchmark are very large.

In the property access section of Figure~\ref{fig:access_objects},
the ``Def'' column shows the fraction
of operations which were statically resolved as definite properties
(\Section\ref{sec:supplemental-analyses}), while the ``PIC'' column shows the fraction which
were not resolved statically but were matched using a fallback mechanism,
polymorphic inline caches \cite{Holzle91}.
The ``Uk'' column is the fraction of operations which were not resolved
either statically or with a PIC and required a call into the VM;
this includes accesses where objects
with many different layouts are used, and accesses on rare kinds of
properties such as those with scripted getters or setters.

An average of 39.4\% of property accesses were resolved as definite properties,
with a much higher average proportion on benchmarks of 80.3\%.
The remainder were by and large handled by PICs, with only 5.5\% of
accesses requiring a VM call.
Together, these suggest that objects on websites are by and large
constructed in a consistent fashion, but that
our detection of definite properties needs
to be more robust on object construction patterns seen on websites but
not on benchmarks.

\subsubsection{Precision Without Barriers}
\label{sec:without_barriers}

To test the practical effect of using type barriers to improve precision,
we repeated the above website tests using a build of Firefox where
subset constraints were used in place of barrier constraints,
and type barriers were not used at all (semantic triggers were still used).
Some of the numbers from these runs are shown in Figure~\ref{fig:without_barriers}.

The precision section shows the fraction of indexed and property accesses which
were inferred as polymorphic, and the arithmetic section shows the fraction
of arithmetic operations where at least one operand type was unknown.
Both sections show the ratio of the given fraction to the comparable fraction
with type barriers enabled.
Overall, with type barriers disabled 42.1\% of accesses are polymorphic and 37.4\%
of arithmetic operations have operands of unknown type; precision is far worse
than with type barriers.
Benchmarks are affected much less than other kinds of sites;
these benchmarks use polymorphic structures much less
than the web at large.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
