\section{Analysis}

We present our analysis in two parts, the static ``may-have-type'' analysis
and the dynamic ``must-have-type'' analysis. The algorithm is based on
Andersen-style constraint-based pointer analysis \cite{AndersenPhD}. The
static analysis, unlike static type reconstruction algorithms, is
intentionally \textit{incomplete} with respect to the semantics of
JavaScript. It does not account for all possible behaviors of expressions and
statements and only generates constraints that model a ``may-have-type''
relation. All behaviors excluded by the type constraints must be detected at
runtime and their effects on types in the program dynamically recorded. The
analysis runs in the browser as functions are trying to execute: code is
analyzed function-at-a-time.

Pointer analysis has a worst-case complexity of $O(n^3)$ and is very
well studied. It has shown---and we reaffirm this with our evaluation---to
perform and scale well despite its cubic worst-case complexity
\cite{Sridharan09}.

%% This paragraph and list doesn't seem to fit in the analysis section, this is more about performance. -ed
%
%Since the analysis runs in a browser as code is trying to execute, both time and space are at a premium and must be minimized. To be viable for deployment, our analysis must satisfy the following:
%
%\begin{itemize}
%
%\item Time and memory used must be linear in the size of the analyzed code.
%
%\item Querying results for an expression must take near-constant time, to avoid changing the performance characteristics of the compiler.
%
%% What does this mean? Interaction between "must" and "if only" is strange. -ed
%\item Results must be correct if only compiled code is analyzed.
%
%\end{itemize}

We describe constraint generation and checks required for a simplified core of
JavaScript expressions and statements, shown in Figure~\ref{fig:js-core}. We
let $f,x$ range over variables, $p$ range over property names, $i$ range over
integer literals, and $s$ range over string literals. The only control flow in
the core language is \code{if}, which tests for definedness. We avoid talking
about functions and function calls in our simplified core; the reader may
think of functions as objects with special domain and codomain properties.

The types over which we are trying to infer is also shown in
Figure~\ref{fig:js-core}. The types can be primitive, \code{undefined},
\code{int}, \code{number}, \code{string}, an object type $o$, or a function
type\footnote{In full JavaScript, we also have the primitive types \code{bool}
  and \code{null}.}. The \code{int} type indicates a number expressible as a
signed 32-bit integer, and is subsumed by \code{number} --- \code{int} is
added to all type sets containing \code{number}. Finally, we have sets of
types which the static analysis computes. The domain and codomain of the
function type are defined over type sets.

\newcommand{\barrier}{\supseteq_\mathcal{B}}

\begin{figure}
\begin{align*}
v & ::= \code{undefined}\ |\ i\ |\ s\ |\ \text{\code{\{\}}} && \text{values}\\
e & ::= v\ |\ x\ |\ e + e\ |\ x.p\ |\ x[i]\ && \text{expressions}\\
s & ::= \code{if}(x)\ s\ \code{else}\ s\ |\ x = e\ |\ x.p = e\ |\ x[i] = e && \text{statements}\\
\\
\tau & ::= \code{undefined}\ |\ \code{int}\ |\ \code{number}\ |\ \code{string}\ |\ o && \text{types}\\
T & ::= \mathcal{P}(\tau) && \text{type sets}\\
\\
C & ::= T \supseteq T\ |\ T \barrier T && \text{constraints}
\end{align*}
\caption{Simplified JavaScript Core, Types, and Constraints}
\label{fig:js-core}
\end{figure}

\begin{figure*}
\begin{align*}
\rulename{Undefined} & \inferrule{}{\judge^e \code{undefined} : T_{\code{undefined}}} &&
\left\{
\begin{array}{l}
T_{\code{undefined}} \supseteq \{\code{undefined}\}
\end{array}
\right\}\\
\rulename{Int} & \inferrule{}{\judge^e i : T_i} &&
\left\{
\begin{array}{l}
T_i \supseteq \{\code{int}\}
\end{array}
\right\}\\
\rulename{String} & \inferrule{}{\judge^e s : T_s} &&
\left\{
\begin{array}{l}
T_s \supseteq \{\code{string}\}
\end{array}
\right\}\\
\rulename{Object} & \inferrule{}{\judge^e \text{\code{\{\}}} : T_{\text{\code{\{\}}}}} &&
\left\{
\begin{array}{l}
T_{\text{\code{\{\}}}} \supseteq \{o\}
\end{array}
\right\} \text{ where $o$ fresh}\\
\rulename{Var} & \inferrule{}{\judge^e x : T_x} && \emptyset\\
\rulename{Add} & \inferrule{\judge^e x : T_x ~~~ \judge^e y : T_y}{\judge^e x + y : T_{x+y}} &&
\left\{
\begin{array}{l}
T_{x+y} \barrier \{\code{int}\}\ |\ \code{int} \in T_x \wedge \code{int} \in T_y,\\
T_{x+y} \supseteq \{\code{number}\}\ |\ \code{int} \in T_x \wedge \code{number} \in T_y,\\
T_{x+y} \supseteq \{\code{number}\}\ |\ \code{number} \in T_x \wedge \code{int} \in T_y,\\
T_{x+y} \supseteq \{\code{string}\}\ |\ \code{string} \in T_x \vee \code{string} \in T_y
\end{array}
\right\}\\
\rulename{Prop} & \inferrule{\judge^e x : T_x}{\judge^e x.p : T_{x.p}} &&
\left\{
\begin{array}{l}
T_{x.p} \barrier \mathit{prop}(o,p)\ |\ o \in T_x
\end{array}
\right\}\\
\rulename{Index} & \inferrule{\judge^e x : T_x}{\judge^e x[i] : T_{x[i]}} &&
\left\{
\begin{array}{l}
T_{x[i]} \barrier \mathit{index}(o)\ |\ o \in T_x
\end{array}
\right\}\\
%\rulename{App} & \inferrule{\judge^e f : T_f ~~~ \judge^e x : T_x}{\judge^e f(x) : T_{f(x)}} &&
%\left\{
%\begin{array}{l}
%T_{\mathit{dom}(f)} \supseteq T_x\ |\ T_{\mathit{dom}(f)} \rightarrow T_{\mathit{cod}(f)} \in T_f,\\
%T_{f(x)} \supseteq T_{\mathit{cod}(f)}\ |\ T_{\mathit{dom}(f)} \rightarrow T_{\mathit{cod}(f)} \in T_f
%\end{array}
%\right\}\\
\\
\rulename{If} & \inferrule{}{\judge^s \code{if}(x)\ s_1\ \code{else}\ s_2 : \text{\textbullet}} &&
\mathcal{C}_s(s_1) \cup \mathcal{C}_s(s_2)\\
\rulename{AssignVar} & \inferrule{\judge^e x : T_x ~~~ \judge^e e : T_e}{\judge^s x = e : \text{\textbullet}} &&
\left\{
\begin{array}{l}
T_x \supseteq T_e
\end{array}
\right\}\\
\rulename{AssignProp} & \inferrule{\judge^e x : T_x ~~~ \judge^e e : T_e}{\judge^s x.p = e : \text{\textbullet}} &&
\left\{
\begin{array}{l}
\mathit{prop}(o,p) \supseteq T_e\ |\ o \in T_x
\end{array}
\right\}\\
\rulename{AssignIndex} & \inferrule{\judge^e x : T_x ~~~ \judge^e e : T_e}{\judge^s x[i] = e : \text{\textbullet}} &&
\left\{
\begin{array}{l}
\mathit{index}(o) \supseteq T_e\ |\ o \in T_x
\end{array}
\right\}
\end{align*}
\caption{Constraint Generation Rules}
\label{fig:constraint-rules}
\end{figure*}

Section~\ref{sec:object-types} describes object types in more detail,
Section~\ref{sec:constraints} describes generation of the type constraints
which forms the static portion of the analysis, and Section~\ref{sec:barriers}
describes type barriers and the other runtime checks which form the dynamic
portion of the analysis.

\subsection{Object Types}
\label{sec:object-types}

To reason about the effects of property accesses, we need type information
for JavaScript objects and their properties.
We associate every JavaScript object with an {\it object type} $o$.
When $o \in T_e$ for some expression $e$, then the possible values
for $e$ when it is executed include all JavaScript objects with type $o$.

Types are assigned to JavaScript objects according to their prototype:
all JavaScript objects with the same type have the same prototype.
Additionally, objects with the same prototype have the same type,
except for plain \code{Object}, \code{Array} and \code{Function} objects.
\code{Object} and \code{Array} objects have the same type if they were
allocated at the same location in a script,
and \code{Function} objects have the same type if they are closures
for the same script.

For the sake of brevity and ease of exposition, our simplified JavaScript core
only contains the ability to construct \code{Object}-prototyped object
literals via the \code{\{\}} syntax.

The type of an object is nominal: it is independent from the properties it
has. Objects which are structurally identical may have different types, and
objects with the same type may have different structures. This is crucial for
efficient analysis. Properties can be added or deleted to JavaScript objects
at any time, and using structural typing would make an object's type a
flow-sensitive property.

Instead, for each object type we compute the {\it possible} properties which
objects of that type can have, and the possible types of those properties.
These are represented as type sets $\mathit{prop}(o,p)$ and
$\mathit{index}(o)$. The set $\mathit{prop}(o,p)$ captures the possible types
of a non-integer property $p$ for objects with type $o$, while
$\mathit{index}(o)$ captures the possible types of all integer properties of
all objects with type $o$.

\subsection{Type Constraints}
\label{sec:constraints}

The static portion of our analysis generates constraints on the flow of types
through the program. We model the semantics of JavaScript by assigning to each
expression a \emph{type set} which denotes the set of types that it may
have. It is important to note that these statically-generated constraints do
not model the entirety of JavaScript semantics. Not every type that the
expression may have is in the statically determined set.

The syntax of constraints are shown in Figure~\ref{fig:js-core}. We have the
standard subset constraint, $\supseteq$, and a \emph{barrier subset
  constraint}, styled $\barrier$. For two type sets $X$ and $Y$, $X \supseteq
Y$ means that all types in $Y$ are propagated to $X$. On the other hand, $X
\barrier Y$ means that only types in $Y$ which have been \emph{observed at
runtime} should be propagated to $X$. Expressions which generate barrier
subset constraints must be monitored at runtime with type barriers, whence the
name. Type barriers are described in detail in Section~\ref{sec:barriers}.

Rules for the constraint generation functions, $\mathcal{C}_e(e)$ for
expressions and $\mathcal{C}_s(s)$ for statements, are shown in
Figure~\ref{fig:constraint-rules}. Statically analyzing a method, then, is
taking the union of the results from applying $\mathcal{C}_s$ to every
statement in the method.

The \textsc{Undefined}, \textsc{Int}, \textsc{String}, and \textsc{Object}
rules for literals and the \textsc{Var} rule for variables are
straightforward.

The \textsc{Add} rule is complex, as addition in JavaScript is very complicated. It is
defined for any combination of values, can perform either a numeric addition,
string concatenation, or even function calls if either of its operands is an
object (calling their \code{valueOf} or \code{toString} members, producing a
number or string).

Using incomplete modeling lets us cut through this complexity. The vast
majority of dynamic additions in JavaScript programs (NUMBERS) are adding two
numbers or concatenating two strings. We statically model exactly these cases,
and use runtime checks to monitor the results produced by adding other
combinations of values, at little runtime cost.

Note that even the integer addition rule we have given is incomplete: the
result will be marked as an integer, ignoring the possibility of
overflow. When addition of two integers overflows, the result is not
expressible in 32 bits, and has type \code{number}. Overflow is extremely
rare, and accounting for it statically would require us to mark the result of
all additions as arbitrary numbers, except in the limited cases where we can
prove no overflow is possible.

Ignoring overflow statically forces us to use runtime checks when overflows
occur. There is no extra runtime cost associated with these checks, as the
code generated for integer additions requires an overflow check regardless.

\textsc{Prop} accesses a named property $p$ from the possible objects referred
to by $x$, with the result the union of $\mathit{prop}(o,p)$ for all such
objects.  This rule is complete only in cases where the object referred to by
$x$ (or its prototype) actually has the $p$ property.  Accesses on properties
which are not actually part of an object simply produce the \code{undefined}
value of type \code{undefined}.

As with integer overflow, accesses on missing properties are rare (NUMBERS),
and yet in most cases it is impractical or impossible to prove that an object
\emph{definitely} has some property. In such cases we should not dilute the
resulting type sets with \code{undefined}. We should instead use runtime
checks to add the \code{undefined} type to accesses which are dynamically
found to be on missing properties. Indeed, all property accesses are coupled
with runtime checks.

\textsc{Index} is similar to \textsc{Prop}, with the added problem that any
property of the object could be accessed.  In JavaScript, \code{x["p"]} is
equivalent to \code{x.p}. If $x$ has the object type $o$, an index operation
can access a potentially infinite number of type sets $\mathit{prop}(o,p)$. We
do not model this case in our core language, as the vast majority of index
operations are on integers, (NUMBERS) which we collapse into a single type set
$\mathit{index}(o)$.  In full JavaScript, any indexed access which is on a
non-integer property, or is on an integer property which is missing from an
object, must be accounted for with runtime checks in the same manner as
\textsc{Prop}.

Our analysis is path-insensitive, so the \textsc{If} rule is simply the union
of the constraints generated by the branches.

\textsc{AssignVar}, \textsc{AssignProp} and \textsc{AssignIndex} invert the
corresponding read expressions.  These rules are complete, except that
\textsc{AssignIndex} presumes that an integer property is being accessed.
Again, in full JavaScript, the effects on $\mathit{prop}(o,p)$ resulting from
assignments to a string index \code{x["p"]} on some $x$ with object type $o$
must be accounted for with runtime checks.

%TODO --- lose \textsc{App}?

%The reader may wonder where function types come from, as our simplified
%JavaScript core does not contain function declarations. Recall that the
%analysis is run function-at-a-time. At the end of analysis, the type sets of
%the formal parameters and the return value are gathered and a function type is
%constructed for the current function. We omit this detail from the
%formalization.

\subsection{Type Barriers}
\label{sec:barriers}

As described in Section~\ref{sec:constraints}, type barriers are a form of
runtime check designed to retain precision and enforce soundness when a
program contains polymorphic code. Type barriers perform two duties: to
propagate previously unobserved types, and to ensure correctness of JIT code
by bailing out of JIT code. When a type barrier is tripped, we recompile the
function it belonged to with the new type information.

In our hybrid system we may propagate types through the constraint graph both
statically and at runtime. Viewed as an attempt to retain precision, type
barriers essentially \emph{defer} static propagation in favor of runtime
propagation. That is, instead of soundly approximating all possible types of
an expression statically, such as a property access or integer addition, we
wait until execution and monitor the types dynamically. If we observe a
previously unobserved type, then we propagate it. This nets us extra
precision, since at runtime we know the exact type an expression has, and many
scenarios which demand sound overapproximation are rare in practice.

Viewed as enforcers of soundness, type barriers are much like dynamic type
casts in Java or C++. In our case, these type casts only succeed on type
identity. For example, in the \textsc{Add} constraint in
Figure~\ref{fig:constraint-rules}, we propagate the \code{int} type
statically, but we still have to ensure that at runtime no overflow occurred.

Let us make this concrete by returning to the example in
Figure~\ref{fig:motivating-example}. The analysis statically determines that
the index access \code{a[i]} in the function \code{use} has the type of
\code{Box}. However, this is possibly unsound, as without doing more
sophisticated interval analysis, \code{a[i]} could be a hole, in which case
its type will be \code{undefined}. This is expressed in constraints as
$T_{\code{a[i]}} \barrier \{\code{Box}\}$, i.e. we have already observed
\code{Box} objects for the index property of \code{a}, but we need to check
that this is indeed the type returned during runtime, and if not, propagate
the new type and mark the function for recompilation.

In the constraint generation rules in Figure~\ref{fig:constraint-rules} we
present three rules which employ type barrers: \textsc{Add},
\textsc{Prop}, and \textsc{Index}. In \textsc{Add}, the barrier is to check
for overflow. The only new type propagated, if any, would be \code{number}. In
\textsc{Prop} and \textsc{Index}, the barrier is primarily intended to retain
precision of generated code for property accesses. We do not want to emit code
for all possible types that a property could have, but only those we have
observed. After all, in the presence of frequently used dynamic constructs
like \code{eval}, any property on any object could be \code{undefined}!

The presence or absence of type barriers for a given subset constraint is not
monotonic with respect to the contents of the type sets in the program.  As
new types are discovered, new type barriers may be required, but existing ones
may become unnecessary.  However, it is always safe to perform the runtime
check for a given barrier, albeit less efficient.

\subsection{Interpreter Warmup}

TODO

\subsection{Supplemental Analysis}

TODO

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
