\section{Analysis}

We present our analysis in two parts, the static ``may-have-type'' analysis
and the dynamic ``must-have-type'' analysis. The algorithm is based on
Andersen-style constraint-based pointer analysis \cite{AndersenPhD}. The
static analysis, unlike static type reconstruction algorithms, is
intentionally \textit{incomplete} with respect to the semantics of
JavaScript. It does not account for all possible behaviors of expressions and
statements and only generates constraints that model a ``may-have-type''
relation. All behaviors excluded by the type constraints must be detected at
runtime and their effects on types in the program dynamically recorded. The
analysis runs in the browser as functions are trying to execute: code is
analyzed function-at-a-time.

Pointer analysis has a worst-case complexity of $O(n^3)$ and is very
well studied. It has shown---and we reaffirm this with our evaluation---to
perform and scale well despite its cubic worst-case complexity
\cite{Sridharan09}.

%% This paragraph and list doesn't seem to fit in the analysis section, this is more about performance. -ed
%
%Since the analysis runs in a browser as code is trying to execute, both time and space are at a premium and must be minimized. To be viable for deployment, our analysis must satisfy the following:
%
%\begin{itemize}
%
%\item Time and memory used must be linear in the size of the analyzed code.
%
%\item Querying results for an expression must take near-constant time, to avoid changing the performance characteristics of the compiler.
%
%% What does this mean? Interaction between "must" and "if only" is strange. -ed
%\item Results must be correct if only compiled code is analyzed.
%
%\end{itemize}

We describe constraint generation and checks required for a simplified core of
JavaScript expressions and statements, shown in Figure~\ref{fig:js-core}. We
let $f,x$ range over variables, $p$ range over property names, $i$ range over
integer literals, and $s$ range over string literals. The only control flow in
the core language is \code{if}, which tests for definedness. We avoid talking
about functions and function calls in our simplified core; the reader may
think of functions as objects with special domain and codomain properties.

The types over which we are trying to infer is also shown in
Figure~\ref{fig:js-core}. The types can be primitive, \code{undefined},
\code{int}, \code{number}, \code{string}, an object type $o$, or a function
type\footnote{In full JavaScript, we also have the primitive types \code{bool}
  and \code{null}.}. The \code{int} type indicates a number expressible as a
signed 32-bit integer, and is subsumed by \code{number} --- \code{int} is
added to all type sets containing \code{number}. Finally, we have sets of
types which the static analysis computes. The domain and codomain of the
function type are defined over type sets.

\newcommand{\barrier}{\supseteq_\mathcal{B}}

\begin{figure}
\begin{align*}
v & ::= \code{undefined}\ |\ i\ |\ s\ |\ \text{\code{\{\}}} && \text{values}\\
e & ::= v\ |\ x\ |\ e + e\ |\ x.p\ |\ x[i]\ && \text{expressions}\\
s & ::= \code{if}(x)\ s\ \code{else}\ s\ |\ x = e\ |\ x.p = e\ |\ x[i] = e && \text{statements}\\
\\
\tau & ::= \code{undefined}\ |\ \code{int}\ |\ \code{number}\ |\ \code{string}\ |\ o && \text{types}\\
T & ::= \mathcal{P}(\tau) && \text{type sets}\\
\\
C & ::= T \supseteq T\ |\ T \barrier T && \text{constraints}
\end{align*}
\caption{Simplified JavaScript Core, Types, and Constraints}
\label{fig:js-core}
\end{figure}

\begin{figure*}
\begin{align*}
\rulename{Undefined} & \inferrule{}{\judge^e \code{undefined} : T_{\code{undefined}}} &&
\left\{
\begin{array}{l}
T_{\code{undefined}} \supseteq \{\code{undefined}\}
\end{array}
\right\}\\
\rulename{Int} & \inferrule{}{\judge^e i : T_i} &&
\left\{
\begin{array}{l}
T_i \supseteq \{\code{int}\}
\end{array}
\right\}\\
\rulename{String} & \inferrule{}{\judge^e s : T_s} &&
\left\{
\begin{array}{l}
T_s \supseteq \{\code{string}\}
\end{array}
\right\}\\
\rulename{Object} & \inferrule{}{\judge^e \text{\code{\{\}}} : T_{\text{\code{\{\}}}}} &&
\left\{
\begin{array}{l}
T_{\text{\code{\{\}}}} \supseteq \{o\}
\end{array}
\right\} \text{ where $o$ fresh}\\
\rulename{Var} & \inferrule{}{\judge^e x : T_x} && \emptyset\\
\rulename{Add} & \inferrule{\judge^e x : T_x ~~~ \judge^e y : T_y}{\judge^e x + y : T_{x+y}} &&
\left\{
\begin{array}{l}
T_{x+y} \supseteq \{\code{int}\}\ |\ \code{int} \in T_x \wedge \code{int} \in T_y,\\
T_{x+y} \supseteq \{\code{number}\}\ |\ \code{int} \in T_x \wedge \code{number} \in T_y,\\
T_{x+y} \supseteq \{\code{number}\}\ |\ \code{number} \in T_x \wedge \code{int} \in T_y,\\
T_{x+y} \supseteq \{\code{string}\}\ |\ \code{string} \in T_x \vee \code{string} \in T_y
\end{array}
\right\}\\
\rulename{Prop} & \inferrule{\judge^e x : T_x}{\judge^e x.p : T_{x.p}} &&
\left\{
\begin{array}{l}
T_{x.p} \barrier \mathit{prop}(o,p)\ |\ o \in T_x
\end{array}
\right\}\\
\rulename{Index} & \inferrule{\judge^e x : T_x}{\judge^e x[i] : T_{x[i]}} &&
\left\{
\begin{array}{l}
T_{x[i]} \barrier \mathit{index}(o)\ |\ o \in T_x
\end{array}
\right\}\\
%\rulename{App} & \inferrule{\judge^e f : T_f ~~~ \judge^e x : T_x}{\judge^e f(x) : T_{f(x)}} &&
%\left\{
%\begin{array}{l}
%T_{\mathit{dom}(f)} \supseteq T_x\ |\ T_{\mathit{dom}(f)} \rightarrow T_{\mathit{cod}(f)} \in T_f,\\
%T_{f(x)} \supseteq T_{\mathit{cod}(f)}\ |\ T_{\mathit{dom}(f)} \rightarrow T_{\mathit{cod}(f)} \in T_f
%\end{array}
%\right\}\\
\\
\rulename{If} & \inferrule{}{\judge^s \code{if}(x)\ s_1\ \code{else}\ s_2 : \text{\textbullet}} &&
\mathcal{C}_s(s_1) \cup \mathcal{C}_s(s_2)\\
\rulename{AssignVar} & \inferrule{\judge^e x : T_x ~~~ \judge^e e : T_e}{\judge^s x = e : \text{\textbullet}} &&
\left\{
\begin{array}{l}
T_x \supseteq T_e
\end{array}
\right\}\\
\rulename{AssignProp} & \inferrule{\judge^e x : T_x ~~~ \judge^e e : T_e}{\judge^s x.p = e : \text{\textbullet}} &&
\left\{
\begin{array}{l}
\mathit{prop}(o,p) \supseteq T_e\ |\ o \in T_x
\end{array}
\right\}\\
\rulename{AssignIndex} & \inferrule{\judge^e x : T_x ~~~ \judge^e e : T_e}{\judge^s x[i] = e : \text{\textbullet}} &&
\left\{
\begin{array}{l}
\mathit{index}(o) \supseteq T_e\ |\ o \in T_x
\end{array}
\right\}
\end{align*}
\caption{Constraint Generation Rules}
\label{fig:constraint-rules}
\end{figure*}

Section~\ref{sec:object-types} describes object types in more detail,
Section~\ref{sec:constraints} describes generation of the type constraints
which forms the static portion of the analysis and the semantic triggers
these require at runtime, and Section~\ref{sec:barriers}
describes the use of type barriers to improve analysis precision.

\subsection{Object Types}
\label{sec:object-types}

To reason about the effects of property accesses, we need type information
for JavaScript objects and their properties.
We associate every JavaScript object with an {\it object type} $o$.
When $o \in T_e$ for some expression $e$, then the possible values
for $e$ when it is executed include all JavaScript objects with type $o$.

Types are assigned to JavaScript objects according to their prototype:
all JavaScript objects with the same type have the same prototype.
Additionally, objects with the same prototype have the same type,
except for plain \code{Object}, \code{Array} and \code{Function} objects.
\code{Object} and \code{Array} objects have the same type if they were
allocated at the same scripted location,
and \code{Function} objects have the same type if they are closures
for the same script.
\code{Object} and \code{Function} objects which represent builtin objects
such as class prototypes, the \code{Math} object and native functions
are given singleton types --- object types which correspond to only a single
JavaScript object.

For the sake of brevity and ease of exposition, our simplified JavaScript core
only contains the ability to construct \code{Object}-prototyped object
literals via the \code{\{\}} syntax.

The type of an object is nominal: it is independent from the properties it
has. Objects which are structurally identical may have different types, and
objects with the same type may have different structures. This is crucial for
efficient analysis. Properties on JavaScript objects can be added or deleted
at any time, and using structural typing would make an object's type a
flow-sensitive property.

Instead, for each object type we compute the {\it possible} properties which
objects of that type can have, and the possible types of those properties.
These are represented as type sets $\mathit{prop}(o,p)$ and
$\mathit{index}(o)$. The set $\mathit{prop}(o,p)$ captures the possible types
of a non-integer property $p$ for objects with type $o$, while
$\mathit{index}(o)$ captures the possible types of all integer properties of
all objects with type $o$.
These sets cover the types of both `own' properties --- those directly held
by the object --- as well as properties inherited from the object's prototype.
We do not show how types are propagated from a prototype's type information
to the instances; since all objects of a type share the same prototype,
this transfer is straightforward.

\subsection{Type Constraints}
\label{sec:constraints}

The static portion of our analysis generates constraints on the flow of types
through the program. We model the semantics of JavaScript by assigning to each
expression a \emph{type set} which denotes the set of types that it may
have. It is important to note that these statically-generated constraints do
not model the entirety of JavaScript semantics. Each constraint is augmented
with triggers to fill in the remaining possible behaviors of the
operation; we informally describe the required triggers for each rule.

The syntax of constraints are shown in Figure~\ref{fig:js-core}. We have the
standard subset constraint, $\supseteq$, and a \emph{barrier subset
  constraint}, styled $\barrier$. For two type sets $X$ and $Y$, $X \supseteq
Y$ means that all types in $Y$ are propagated to $X$. On the other hand, $X
\barrier Y$ means that if $Y$ contains types that are not in $X$, then a
runtime type barrier is required which can dynamically update the types in $X$.
Type barriers are described in detail in Section~\ref{sec:barriers}.

Rules for the constraint generation functions, $\mathcal{C}_e(e)$ for
expressions and $\mathcal{C}_s(s)$ for statements, are shown in
Figure~\ref{fig:constraint-rules}. Statically analyzing a method, then, is
taking the union of the results from applying $\mathcal{C}_s$ to every
statement in the method.

The \textsc{Undefined}, \textsc{Int}, \textsc{String}, and \textsc{Object}
rules for literals and the \textsc{Var} rule for variables are
straightforward.

The \textsc{Add} rule is complex, as addition in JavaScript is very complicated. It is
defined for any combination of values, can perform either a numeric addition,
string concatenation, or even function calls if either of its operands is an
object (calling their \code{valueOf} or \code{toString} members, producing a
number or string).

Using incomplete modeling lets us cut through this complexity.
Additions in JavaScript programs are typically used to add two numbers
or concatenate a string with something else.
We statically model exactly these cases,
and use semantic triggers to monitor the results produced by adding other
combinations of values, at little runtime cost.

Note that even the integer addition rule we have given is incomplete: the
result will be marked as an integer, ignoring the possibility of
overflow. When addition of two integers overflows, the result is not
expressible in 32 bits, and has type \code{number}.
Integer overflows are very rare, and as described in Section~\ref{XXX}
we avoid pessimistically marking all possibly-overflowing additions as producing
a double, by detecting overflowing additions dynamically
and using a trigger to mark the addition's result as a double.

\textsc{Prop} accesses a named property $p$ from the possible objects referred
to by $x$, with the result the union of $\mathit{prop}(o,p)$ for all such
objects.  This rule is complete only in cases where the object referred to by
$x$ (or its prototype) actually has the $p$ property.  Accesses on properties
which are not actually part of an object simply produce the \code{undefined}
value of type \code{undefined}.

As with integer overflow, accesses on missing properties are rare,
and yet in most cases it is impractical or impossible to prove that an object
\emph{definitely} has some property. In such cases we should not dilute the
resulting type sets with \code{undefined}. We instead use a trigger
on execution paths accessing a missing property to update the result type
of the access with \code{undefined}.

\textsc{Index} is similar to \textsc{Prop}, with the added problem that any
property of the object could be accessed.  In JavaScript, \code{x["p"]} is
equivalent to \code{x.p}. If $x$ has the object type $o$, an index operation
can access a potentially infinite number of type sets $\mathit{prop}(o,p)$.
Figuring out exactly which such properties are possible is generally
intractable. We do not model such arbitrary accesses at all, and treat
all index operations as operating on an integer,
 which we collapse into a single type set
$\mathit{index}(o)$.  In full JavaScript, any indexed access which is on a
non-integer property, or is on an integer property which is missing from an
object, must be accounted for with triggers in the same manner as
\textsc{Prop}.

Our analysis is flow-insensitive, so the \textsc{If} rule is simply the union
of the constraints generated by the branches.

\textsc{AssignVar}, \textsc{AssignProp} and \textsc{AssignIndex} invert the
corresponding read expressions.  These rules are complete, except that
\textsc{AssignIndex} presumes that an integer property is being accessed.
Again, in full JavaScript, the effects on $\mathit{prop}(o,p)$ resulting from
assignments to a string index \code{x["p"]} on some $x$ with object type $o$
must be accounted for with runtime checks.

%TODO --- lose \textsc{App}?

\subsection{Type Barriers}
\label{sec:barriers}

As described in Section~\ref{XXX}, type barriers are dynamic type checks
inserted to improve analysis precision in the presence
of polymorphic code.
Propagation along an assignment $X = Y$ can be modeled
statically as a subset
constraint $X \supseteq Y$ or dynamically as a barrier constraint
$X \barrier Y$.
It is always safe to use one in place of the other; in Section~\ref{XXX}
we show the effect of always using subset constraints in lieu of
barrier constraints.

For a barrier constraint $X \barrier Y$, a type barrier is required whenever
$X \not\supseteq Y$. The barrier dynamically checks that all values
flowing across the assignment are actually in $X$, and updates $X$ whenever
values of a new type are encountered.
$X$ will contain only the types of values which
have ever actually been observed at the assignment, and a barrier will be
required if there are additional types in $Y$ which could be observed.

Type barriers are much like dynamic type casts in Java: assignments from a
more general type to a more specific type are possible as long as a
dynamic test occurs for conformance.
However, rather than throw an exception (as in Java) a tripped type barrier will
despecialize the target of the assignment.

The presence or absence of type barriers for a given barrier constraint is not
monotonic with respect to the contents of the type sets in the program.  As
new types are discovered, new type barriers may be required, and existing ones
may become unnecessary.  However, it is always safe to perform the runtime
tests for a given barrier, albeit less efficient.

In the constraint generation rules in Figure~\ref{fig:constraint-rules} we
present two rules which employ type barrers:
\textsc{Prop}, and \textsc{Index}. In practice, we also use type barriers for
call argument binding to precisely model polymorphic call sites where
only certain combinations of argument types and callee functions are possible.
Barriers could be used for other types of assignments, but we do not do so.
Allowing barriers in new places is unlikely to significantly change the total
number of required barriers --- improving precision by adding barriers in one
place can make barriers in another place unnecessary.
The main cost is the extra compiler complexity required to support new
kinds of barriers, and we may take such steps in the future.

\subsection{Supplemental Analysis}

In many cases type information itself is insufficient to generate code
which performs comparably to a statically typed
language such as Java.
Integer addition requires checks for overflow,
index operations on arrays require checks for holes in the middle of the array,
and property accesses require determining whether the object has the property
and the physical location where the property is stored.
To reach a speed closer to that of a statically typed language, these checks must
be eliminated in as many cases as possible.

Eliminating such checks requires more detailed analysis information.
Rather than build additional complexity into the type analysis itself,
we use supplemental analyses which leverage type information but do not
modify the set of inferred types.
The remainder of this section briefly describes our handling of the above
situations.
We do several other supplemental analyses, but these are the most important.

\subsubsection{Integer Overflow}

In the execution of a JavaScript program, the overall cost of doing integer
overflow checks is very small.
On kernels which do many additions, however, the cost can become significant.
We have measured overflow check overhead at 10-20\% of total execution
time on microbenchmarks.

Using type information, we normally know statically where integers are being
added. We use two techniques on those sites to remove overflow checks.
First, for simple additions in a loop (mainly loop counters) we try to use
the loop termination condition to compute a range
check which can be hoisted from the loop, a standard technique \cite{XXX}
which can only be performed for JavaScript with type information available.
Second, integer additions which are used as inputs to bitwise operators
do not need overflow checks, as bitwise operators truncate their inputs to 32
bit integers.

\subsubsection{Packed Arrays}

Holes in the middle of an array are rare.
Arrays are usually constructed by writing to their elements in ascending
order, with no gaps; we call these arrays {\it packed}.
There are a large number of ways packed arrays can be constructed, however,
which makes it difficult to statically prove an array is packed.
Instead, we dynamically detect out-of-order writes on an array,
and mark the type of the array object as possibly not packed.
If an object type has never been marked as not packed, then all objects
with that type are packed arrays.

When compiling an index operation, if the type set of the accessed object
contains no object types marked as possibly not packed, then the operation
must be on a packed array.
In such cases, the generated code does not need to check for a hole in the
middle of the array, and only needs to perform a bounds check. In turn, the bounds check can
often be hoisted from loop bodies in the same manner as integer overflow
checks.

The packed status of an object type can change dynamically due to out-of-order
writes, possibly invalidating JIT code.
This forces recompilation in the same way as type changes due to semantic
triggers and tripped type barriers do.

\subsubsection{Definite Properties}

JavaScript lacks structural typing, and objects are conceptually maps
from property names to values, where properties can be freely added,
deleted or reconfigured by scripts.
Internally, objects are laid out as an array of values with a mapping from
property names to slots in that array.

If a property access can be resolved statically to a particular slot in the
array, then the access is on a {\it definite} property and can be compiled
as a direct lookup. This is comparable to
field accesses on monomorphic receivers in a language with static object layouts,
such as Java or C++.

We identify definite property accesses in three ways.
First, if the property access is on an object type which is a singleton,
we know the exact JavaScript object being accessed and can use the slot
in its property map.
Second, object literals allocated in the same place have the same type,
and definite properties can be picked up from the order the literal
adds properties.
Third, objects created by calling \code{new} on the same function will have the
same prototype (unless the function's \code{prototype} property is overwritten),
and we analyze the function's body to identify properties it definitely
adds before letting the new object escape.

These techniques are sensitive to properties being deleted or
reconfigured, and if such events happen then JIT code will be invalidated
in the same way as by packed array or type set changes.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
