\section{Analysis}

We present our analysis in two parts, the static ``may-have-type'' analysis
and the dynamic ``must-have-type'' analysis. The algorithm is based on
Andersen-style constraint-based pointer analysis \cite{AndersenPhD}. The
static analysis, unlike static type reconstruction algorithms, is
intentionally \textit{incomplete} with respect to the semantics of
JavaScript. It does not account for all possible behaviors of expressions and
statements and only generates constraints that model a ``may-have-type''
relation. All behaviors excluded by the type constraints must be detected at
runtime and their effects on types in the program dynamically recorded. The
analysis runs in the browser as functions are trying to execute: code is
analyzed function-at-a-time.

Pointer analysis has a worst-case complexity of $O(n^3)$ and is very
well studied. It has shown---and we reaffirm this with our evaluation---to
perform and scale well despite its cubic worst-case complexity
\cite{Sridharan09}.

%% This paragraph and list doesn't seem to fit in the analysis section, this is more about performance. -ed
%
%Since the analysis runs in a browser as code is trying to execute, both time and space are at a premium and must be minimized. To be viable for deployment, our analysis must satisfy the following:
%
%\begin{itemize}
%
%\item Time and memory used must be linear in the size of the analyzed code.
%
%\item Querying results for an expression must take near-constant time, to avoid changing the performance characteristics of the compiler.
%
%% What does this mean? Interaction between "must" and "if only" is strange. -ed
%\item Results must be correct if only compiled code is analyzed.
%
%\end{itemize}

We describe constraint generation and checks required for a simplified core of
JavaScript expressions and statements, shown in Figure~\ref{fig:js-core}. We
let $f,x$ range over variables, $p$ range over property names, $i$ range over
integer literals, and $s$ range over string literals. The only control flow in
the core language is \code{if}, which tests for definedness. We avoid talking
about functions and function calls in our simplified core; the reader may
think of functions as objects with special domain and codomain properties.

The types over which we are trying to infer is also shown in
Figure~\ref{fig:js-core}. The types can be primitive, \code{undefined},
\code{int}, \code{number}, \code{string}, an object type $o$, or a function
type\footnote{In full JavaScript, we also have the primitive types \code{bool}
  and \code{null}.}. The \code{int} type indicates a number expressible as a
signed 32-bit integer, and is subsumed by \code{number} --- \code{int} is
added to all type sets containing \code{number}. Finally, we have sets of
types which the static analysis computes. The domain and codomain of the
function type are defined over type sets.

\newcommand{\barrier}{\supseteq_\mathcal{B}}

\begin{figure}
\begin{align*}
v & ::= \code{undefined}\ |\ i\ |\ s\ |\ \text{\code{\{\}}} && \text{values}\\
e & ::= v\ |\ x\ |\ e + e\ |\ x.p\ |\ x[i]\ && \text{expressions}\\
s & ::= \code{if}(x)\ s\ \code{else}\ s\ |\ x = e\ |\ x.p = e\ |\ x[i] = e && \text{statements}\\
\\
\tau & ::= \code{undefined}\ |\ \code{int}\ |\ \code{number}\ |\ \code{string}\ |\ o && \text{types}\\
T & ::= \mathcal{P}(\tau) && \text{type sets}\\
\\
C & ::= T \supseteq T\ |\ T \barrier T && \text{constraints}
\end{align*}
\caption{Simplified JavaScript Core, Types, and Constraints}
\label{fig:js-core}
\end{figure}

\begin{figure*}
\begin{align*}
\rulename{Undefined} & \inferrule{}{\judge^e \code{undefined} : T_{\code{undefined}}} &&
\left\{
\begin{array}{l}
T_{\code{undefined}} \supseteq \{\code{undefined}\}
\end{array}
\right\}\\
\rulename{Int} & \inferrule{}{\judge^e i : T_i} &&
\left\{
\begin{array}{l}
T_i \supseteq \{\code{int}\}
\end{array}
\right\}\\
\rulename{String} & \inferrule{}{\judge^e s : T_s} &&
\left\{
\begin{array}{l}
T_s \supseteq \{\code{string}\}
\end{array}
\right\}\\
\rulename{Object} & \inferrule{}{\judge^e \text{\code{\{\}}} : T_{\text{\code{\{\}}}}} &&
\left\{
\begin{array}{l}
T_{\text{\code{\{\}}}} \supseteq \{o\}
\end{array}
\right\} \text{ where $o$ fresh}\\
\rulename{Var} & \inferrule{}{\judge^e x : T_x} && \emptyset\\
\rulename{Add} & \inferrule{\judge^e x : T_x ~~~ \judge^e y : T_y}{\judge^e x + y : T_{x+y}} &&
\left\{
\begin{array}{l}
T_{x+y} \barrier \{\code{int}\}\ |\ \code{int} \in T_x \wedge \code{int} \in T_y,\\
T_{x+y} \supseteq \{\code{number}\}\ |\ \code{int} \in T_x \wedge \code{number} \in T_y,\\
T_{x+y} \supseteq \{\code{number}\}\ |\ \code{number} \in T_x \wedge \code{int} \in T_y,\\
T_{x+y} \supseteq \{\code{string}\}\ |\ \code{string} \in T_x \vee \code{string} \in T_y
\end{array}
\right\}\\
\rulename{Prop} & \inferrule{\judge^e x : T_x}{\judge^e x.p : T_{x.p}} &&
\left\{
\begin{array}{l}
T_{x.p} \barrier \mathit{prop}(o,p)\ |\ o \in T_x
\end{array}
\right\}\\
\rulename{Index} & \inferrule{\judge^e x : T_x}{\judge^e x[i] : T_{x[i]}} &&
\left\{
\begin{array}{l}
T_{x[i]} \barrier \mathit{index}(o)\ |\ o \in T_x
\end{array}
\right\}\\
%\rulename{App} & \inferrule{\judge^e f : T_f ~~~ \judge^e x : T_x}{\judge^e f(x) : T_{f(x)}} &&
%\left\{
%\begin{array}{l}
%T_{\mathit{dom}(f)} \supseteq T_x\ |\ T_{\mathit{dom}(f)} \rightarrow T_{\mathit{cod}(f)} \in T_f,\\
%T_{f(x)} \supseteq T_{\mathit{cod}(f)}\ |\ T_{\mathit{dom}(f)} \rightarrow T_{\mathit{cod}(f)} \in T_f
%\end{array}
%\right\}\\
\\
\rulename{If} & \inferrule{}{\judge^s \code{if}(x)\ s_1\ \code{else}\ s_2 : \text{\textbullet}} &&
\mathcal{C}_s(s_1) \cup \mathcal{C}_s(s_2)\\
\rulename{AssignVar} & \inferrule{\judge^e x : T_x ~~~ \judge^e e : T_e}{\judge^s x = e : \text{\textbullet}} &&
\left\{
\begin{array}{l}
T_x \supseteq T_e
\end{array}
\right\}\\
\rulename{AssignProp} & \inferrule{\judge^e x : T_x ~~~ \judge^e e : T_e}{\judge^s x.p = e : \text{\textbullet}} &&
\left\{
\begin{array}{l}
\mathit{prop}(o,p) \supseteq T_e\ |\ o \in T_x
\end{array}
\right\}\\
\rulename{AssignIndex} & \inferrule{\judge^e x : T_x ~~~ \judge^e e : T_e}{\judge^s x[i] = e : \text{\textbullet}} &&
\left\{
\begin{array}{l}
\mathit{index}(o) \supseteq T_e\ |\ o \in T_x
\end{array}
\right\}
\end{align*}
\caption{Constraint Generation Rules}
\label{fig:constraint-rules}
\end{figure*}

Section~\ref{sec:object-types} describes object types in more detail,
Section~\ref{sec:constraints} describes generation of the type constraints
which forms the static portion of the analysis and the semantic triggers
these require at runtime, and Section~\ref{sec:barriers}
describes the use of type barriers to improve analysis precision.

\subsection{Object Types}
\label{sec:object-types}

To reason about the effects of property accesses, we need type information
for JavaScript objects and their properties.
We associate every JavaScript object with an {\it object type} $o$.
When $o \in T_e$ for some expression $e$, then the possible values
for $e$ when it is executed include all JavaScript objects with type $o$.

Types are assigned to JavaScript objects according to their prototype:
all JavaScript objects with the same type have the same prototype.
Additionally, objects with the same prototype have the same type,
except for plain \code{Object}, \code{Array} and \code{Function} objects.
\code{Object} and \code{Array} objects have the same type if they were
allocated at the same scripted location,
and \code{Function} objects have the same type if they are closures
for the same script.

For the sake of brevity and ease of exposition, our simplified JavaScript core
only contains the ability to construct \code{Object}-prototyped object
literals via the \code{\{\}} syntax.

The type of an object is nominal: it is independent from the properties it
has. Objects which are structurally identical may have different types, and
objects with the same type may have different structures. This is crucial for
efficient analysis. Properties on Javascript objects can be added or deleted
at any time, and using structural typing would make an object's type a
flow-sensitive property.

Instead, for each object type we compute the {\it possible} properties which
objects of that type can have, and the possible types of those properties.
These are represented as type sets $\mathit{prop}(o,p)$ and
$\mathit{index}(o)$. The set $\mathit{prop}(o,p)$ captures the possible types
of a non-integer property $p$ for objects with type $o$, while
$\mathit{index}(o)$ captures the possible types of all integer properties of
all objects with type $o$.
These sets cover the types of both `own' properties --- those directly held
by the object --- as well as properties inherited from the object's prototype.
We do not show how types are propagated from a prototype's type information
to the instances; since all objects of a type share the same prototype,
this transfer is straightforward.

\subsection{Type Constraints}
\label{sec:constraints}

The static portion of our analysis generates constraints on the flow of types
through the program. We model the semantics of JavaScript by assigning to each
expression a \emph{type set} which denotes the set of types that it may
have. It is important to note that these statically-generated constraints do
not model the entirety of JavaScript semantics. Each constraint is augmented
with triggers to fill in the remaining possible behaviors of the
operation; we informally describe the required triggers for each rule.

The syntax of constraints are shown in Figure~\ref{fig:js-core}. We have the
standard subset constraint, $\supseteq$, and a \emph{barrier subset
  constraint}, styled $\barrier$. For two type sets $X$ and $Y$, $X \supseteq
Y$ means that all types in $Y$ are propagated to $X$. On the other hand, $X
\barrier Y$ means that if $Y$ contains types that are not in $X$, then a
runtime type barrier is required which can dynamically update the types in $X$.
Type barriers are described in detail in Section~\ref{sec:barriers}.

Rules for the constraint generation functions, $\mathcal{C}_e(e)$ for
expressions and $\mathcal{C}_s(s)$ for statements, are shown in
Figure~\ref{fig:constraint-rules}. Statically analyzing a method, then, is
taking the union of the results from applying $\mathcal{C}_s$ to every
statement in the method.

The \textsc{Undefined}, \textsc{Int}, \textsc{String}, and \textsc{Object}
rules for literals and the \textsc{Var} rule for variables are
straightforward.

The \textsc{Add} rule is complex, as addition in JavaScript is very complicated. It is
defined for any combination of values, can perform either a numeric addition,
string concatenation, or even function calls if either of its operands is an
object (calling their \code{valueOf} or \code{toString} members, producing a
number or string).

Using incomplete modeling lets us cut through this complexity.
Additions in Javascript programs are typically used to add two numbers
or concatenate a string with something else.
We statically model exactly these cases,
and use semantic triggers to monitor the results produced by adding other
combinations of values, at little runtime cost.

Note that even the integer addition rule we have given is incomplete: the
result will be marked as an integer, ignoring the possibility of
overflow. When addition of two integers overflows, the result is not
expressible in 32 bits, and has type \code{number}.
Integer overflows are very rare, and as described in Section~\ref{XXX}
we avoid pessimistically marking all possibly-overflowing additions as producing
a double, by detecting overflowing additions dynamically
and using a trigger to mark the addition's result as a double.

\textsc{Prop} accesses a named property $p$ from the possible objects referred
to by $x$, with the result the union of $\mathit{prop}(o,p)$ for all such
objects.  This rule is complete only in cases where the object referred to by
$x$ (or its prototype) actually has the $p$ property.  Accesses on properties
which are not actually part of an object simply produce the \code{undefined}
value of type \code{undefined}.

As with integer overflow, accesses on missing properties are rare,
and yet in most cases it is impractical or impossible to prove that an object
\emph{definitely} has some property. In such cases we should not dilute the
resulting type sets with \code{undefined}. We instead use a trigger
on execution paths accessing a missing property to update the result type
of the access with \code{undefined}.

\textsc{Index} is similar to \textsc{Prop}, with the added problem that any
property of the object could be accessed.  In JavaScript, \code{x["p"]} is
equivalent to \code{x.p}. If $x$ has the object type $o$, an index operation
can access a potentially infinite number of type sets $\mathit{prop}(o,p)$.
Figuring out exactly which such properties are possible is generally
intractable. We do not model such arbitrary accesses at all, and treat
all index operations as operating on an integer,
 which we collapse into a single type set
$\mathit{index}(o)$.  In full JavaScript, any indexed access which is on a
non-integer property, or is on an integer property which is missing from an
object, must be accounted for with triggers in the same manner as
\textsc{Prop}.

Our analysis is flow-insensitive, so the \textsc{If} rule is simply the union
of the constraints generated by the branches.

\textsc{AssignVar}, \textsc{AssignProp} and \textsc{AssignIndex} invert the
corresponding read expressions.  These rules are complete, except that
\textsc{AssignIndex} presumes that an integer property is being accessed.
Again, in full JavaScript, the effects on $\mathit{prop}(o,p)$ resulting from
assignments to a string index \code{x["p"]} on some $x$ with object type $o$
must be accounted for with runtime checks.

%TODO --- lose \textsc{App}?

%The reader may wonder where function types come from, as our simplified
%JavaScript core does not contain function declarations. Recall that the
%analysis is run function-at-a-time. At the end of analysis, the type sets of
%the formal parameters and the return value are gathered and a function type is
%constructed for the current function. We omit this detail from the
%formalization.

\subsection{Type Barriers}
\label{sec:barriers}

As described in Section~\ref{XXX}, type barriers are dynamic type checks
inserted to improve analysis precision in the presence
of polymorphic code.
Propagation along an assignment $X = Y$ can be modeled
statically as a subset
constraint $X \supseteq Y$ or dynamically as a barrier constraint
$X \barrier Y$.
It is always safe to use one in place of the other; in Section~\ref{XXX}
we show the effect of always using subset constraints in lieu of
barrier constraints.

For a barrier constraint $X \barrier Y$, a type barrier is required whenever
$X \not\supseteq Y$. The barrier dynamically checks that all values
flowing across the assignment are actually in $X$, and updates $X$ whenever
values of a new type are encountered.
$X$ will contain only the types of values which
have ever actually been observed at the assignment, and a barrier will be
required if there are additional types in $Y$ which could be observed.

Type barriers are much like dynamic type casts in Java: assignments from a
more general type to a more specific type are possible as long as a
dynamic test occurs for conformance.
However, rather than throw an exception (as in Java) a tripped type barrier will
despecialize the target of the assignment.

The presence or absence of type barriers for a given subset constraint is not
monotonic with respect to the contents of the type sets in the program.  As
new types are discovered, new type barriers may be required, but existing ones
may become unnecessary.  However, it is always safe to perform the runtime
check for a given barrier, albeit less efficient.

In the constraint generation rules in Figure~\ref{fig:constraint-rules} we
present two rules which employ type barrers:
\textsc{Prop}, and \textsc{Index}. In practice, we also use type barriers for
call argument bindings, to precisely model polymorphic call sites where
only certain combinations of argument types and callee functions are possible.
Barriers could be used for other types of assignments, but we do not do so.
Allowing barriers in new places is unlikely to significantly change the total
number of required barriers --- improving precision by adding barriers in one
place can make barriers in another place unnecessary.
The main cost is the extra compiler complexity required to support
barriers for different assignments, and we may take such steps in the future.

\subsection{Interpreter Warmup}

TODO

\subsection{Supplemental Analysis}

TODO

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
