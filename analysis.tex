\section{Analysis}
\label{sec:analysis}

We present our analysis in two parts, the static ``may-have-type'' analysis
and the dynamic ``must-have-type'' analysis. The algorithm is based on
Andersen-style (inclusion based) pointer analysis \cite{AndersenPhD}. The
static analysis is
intentionally unsound with respect to the semantics of
JavaScript. It does not account for all possible behaviors of expressions and
statements and only generates constraints that model a ``may-have-type''
relation. All behaviors excluded by the type constraints must be detected at
runtime and their effects on types in the program dynamically recorded. The
analysis runs in the browser as functions are trying to execute: code is
analyzed function-at-a-time.

Inclusion based pointer analysis has a worst-case complexity of $O(n^3)$
and is very
well studied. It has been shown to
perform and scale well despite its cubic worst-case complexity
\cite{Sridharan09}.
We reaffirm this with our evaluation;
even when analyzing large amounts of code the presence of runtime checks keeps type sets
small and constraints easy to resolve.

%% This paragraph and list doesn't seem to fit in the analysis section, this is more about performance. -ed
%
%Since the analysis runs in a browser as code is trying to execute, both time and space are at a premium and must be minimized. To be viable for deployment, our analysis must satisfy the following:
%
%\begin{itemize}
%
%\item Time and memory used must be linear in the size of the analyzed code.
%
%\item Querying results for an expression must take near-constant time, to avoid changing the performance characteristics of the compiler.
%
%% What does this mean? Interaction between "must" and "if only" is strange. -ed
%\item Results must be correct if only compiled code is analyzed.
%
%\end{itemize}

We describe constraint generation and checks required for a simplified core of
JavaScript expressions and statements, shown in Figure~\ref{fig:js-core}. We
let $f,x,y$ range over variables, $p$ range over property names, $i$ range over
integer literals, and $s$ range over string literals. The only control flow in
the core language is \code{if}, which tests for definedness, and via anonymous
functions \code{fn}.

The types over which we are trying to infer are also shown in
Figure~\ref{fig:js-core}. The types can be primitive or an object type
$o$.\footnote{In full JavaScript, we also have the primitive types \code{bool}
  and \code{null}.} The \code{int} type indicates a number expressible as a
signed 32-bit integer and is subsumed by \code{number} --- \code{int} is added
to all type sets containing \code{number}. There is no arrow type for
functions, as functions are treated as objects with special argument and
return properties, as we show below. Finally, we have sets of types
which the analysis computes.

\newcommand{\barrier}{\supseteq_\mathcal{B}}

\begin{figure}
\begin{align*}
v & ::= \code{undefined}\ |\ i\ |\ s\ |\ \text{\code{\{\}}}\ |\ \code{fn}(x)\ s\ \code{ret}\ e&& \text{values}\\
e & ::= v\ |\ x\ |\ x + y\ |\ x.p\ |\ x[i]\ |\ f(x) && \text{expressions}\\
s & ::= \code{if}(x)\ s\ \code{else}\ s\ |\ x = e\ |\ x.p = e\ |\ x[i] = e && \text{statements}\\[0.7ex]
\tau & ::= \code{undefined}\ |\ \code{int}\ |\ \code{number}\ |\ \code{string}\ |\ o && \text{types}\\
T & ::= \mathcal{P}(\tau) && \text{type sets}\\[0.8ex]
A & ::= \tau \in T\ |\ A \wedge A\ |\ A \vee A && \text{antecedents}\\
C & ::= T \supseteq T\ |\ T \barrier T\ |\ A \Implies C\ |\ \forall o \in T \Implies C && \text{constraints}
\end{align*}
\caption{Simplified JavaScript Core, Types, and Constraints}
\label{fig:js-core}
\end{figure}


%\Section\ref{sec:object-types} describes object types in more detail,
%\Section\ref{sec:constraints} describes generation of the type constraints
%which forms the static portion of the analysis and the semantic triggers
%these require at runtime, and \Section\ref{sec:analysis-barriers}
%describes the use of type barriers to improve analysis precision.

\subsection{Object Types}
\label{sec:object-types}

To reason about the effects of property accesses, we need type information
for JavaScript objects and their properties.
Each object is immutably assigned an {\it object type} $o$.
When $o \in T_e$ for some expression $e$, then the possible values
for $e$ when it is executed include all objects with type $o$.

For the sake of brevity and ease of exposition, our simplified JavaScript core
only contains the ability to construct \code{Object}-prototyped object
literals via the \code{\{\}} syntax;
two objects have the same type when they were allocated via the same literal.

In full JavaScript, types are assigned to objects according to their prototype:
all objects with the same type have the same prototype.
Additionally, objects with the same prototype have the same type,
except for plain \code{Object}, \code{Array} and \code{Function} objects.
\code{Object} and \code{Array} objects have the same type if they were
allocated at the same source location,
and \code{Function} objects have the same type if they are closures
for the same script.
\code{Object} and \code{Function} objects which represent builtin objects
such as class prototypes, the \code{Math} object and native functions
are given unique types, to aid later optimizations
(\Section\ref{sec:definite-properties}).

The type of an object is nominal: it is independent from the properties it
has. Objects which are structurally identical may have different types, and
objects with the same type may have different structures. This is crucial for
efficient analysis. JavaScript allows addition or deletion of object properties
at any time. Using structural typing would make an object's type a
flow-sensitive property, making precise inference harder to achieve.

Instead, for each object type we compute the possible properties which
objects of that type can have and the possible types of those properties.
These are denoted as type sets $\mathit{prop}(o,p)$ and
$\mathit{index}(o)$. The set $\mathit{prop}(o,p)$ captures the possible types
of a non-integer property $p$ for objects with type $o$, while
$\mathit{index}(o)$ captures the possible types of all integer properties of
all objects with type $o$.
These sets cover the types of both ``own'' properties (those directly held
by the object) as well as properties inherited from the object's prototype.
\code{Function} objects have two additional type sets
$\mathit{arg}(o)$ and $\mathit{ret}(o)$, denoting
the possible types that the function's single parameter and return value can have.
%We do not show how types are propagated from a prototype's type information
%to the instances; since all objects of a type share the same prototype,
%this transfer is straightforward.

\subsection{Type Constraints}
\label{sec:constraints}

\begin{figure}
$$\mathcal{C} : (\text{expression} + \text{statement}) \rightarrow \mathcal{P}(C)$$
\begin{align*}
& \code{undefined} &&
\left\{
\begin{array}{l}
T_{\code{undefined}} \supseteq \{\code{undefined}\}
\end{array}
\right\}
\tag{\sc Undef}\\
& i &&
\left\{
\begin{array}{l}
T_i \supseteq \{\code{int}\}
\end{array}
\right\} \tag{\sc Int}\\
& s &&
\left\{
\begin{array}{l}
T_s \supseteq \{\code{string}\}
\end{array}
\right\} \tag{\sc Str}\\
& \text{\code{\{\}}} &&
\left\{
\begin{array}{l}
T_{\text{\code{\{\}}}} \supseteq \{o\}
\end{array}
\right\} \text{ where $o$ fresh} \tag{\sc Obj}\\
& \mathrlap{\text{\code{fn}}(x)\ s\ \code{ret}\ e} \\
& \mathrlap{\
\left\{
\begin{array}{l}
T_{\text{\code{fn}}(x)\ s\ \code{ret}\ e} \supseteq \{o\},\\
T_x \barrier \mathit{arg}(o),\\
\mathit{ret}(o) \supseteq T_e
\end{array}
\right\} \text{ where $o$ fresh}} \tag{\sc Fun}\\
& x && \emptyset \tag{\sc Var}\\
& x + y \\
& \mathrlap{\ \left\{
\begin{array}{l}
\code{int} \in T_x \wedge \code{int} \in T_y \Implies T_{x+y} \supseteq \{\code{int}\},\\
\code{int} \in T_x \wedge \code{number} \in T_y \Implies T_{x+y} \supseteq \{\code{number}\},\\
\code{number} \in T_x \wedge \code{int} \in T_y \Implies T_{x+y} \supseteq \{\code{number}\},\\
\code{string} \in T_x \vee \code{string} \in T_y \Implies T_{x+y} \supseteq \{\code{string}\}
\end{array}
\right\}} \tag{\sc Add}\\
& x.p &&
\left\{
\begin{array}{l}
\forall o \in T_x \Implies T_{x.p} \barrier \mathit{prop}(o,p)
\end{array}
\right\} \tag{\sc Prop}\\
& x[i] &&
\left\{
\begin{array}{l}
\forall o \in T_x \Implies T_{x[i]} \barrier \mathit{index}(o)
\end{array}
\right\} \tag{\sc Index}\\
& x = e &&
\left\{
\begin{array}{l}
T_x \supseteq T_e
\end{array}
\right\} \tag{\sc A-Var}\\
& x.p = e &&
\left\{
\begin{array}{l}
\forall o \in T_x \Implies \mathit{prop}(o,p) \supseteq T_e
\end{array}
\right\} \tag{\sc A-Prop}\\
& x[i] = e &&
\left\{
\begin{array}{l}
\forall o \in T_x \Implies \mathit{index}(o) \supseteq T_e
\end{array}
\right\} \tag{\sc A-Index}\\
& f(x) &&
\left\{
\begin{array}{l}
\forall o \in T_f \Implies \mathit{arg}(o) \supseteq x,\\
\forall o \in T_f \Implies T_{f(x)} \supseteq \mathit{ret}(o)
\end{array}
\right\} \tag{\sc App}\\
& \mathrlap{\code{if}(x)\ s_1\ \code{else}\ s_2 \quad
\mathcal{C}(s_1) \cup \mathcal{C}(s_2)} \tag{\sc If}
\end{align*}
\caption{Constraint Generation Function $\mathcal{C}$}
\label{fig:constraint-rules}
\end{figure}

The static portion of our analysis generates constraints
modeling the flow of types
through the program. We assign to each
expression $e$ a type set representing the set of types it may have at runtime, denoted $T_e$.
These constraints are
unsound with respect to JavaScript semantics. Each constraint is augmented
with triggers to fill in the remaining possible behaviors of the
operation.
For each rule, we informally describe the required triggers.

The grammar of constraints are shown in Figure~\ref{fig:js-core}. We have the
standard subset constraint, $\supseteq$, a \emph{barrier subset
  constraint}, $\barrier$, the simple conditional constraint, $\Implies$, and the universal conditional constraint.
For two type sets $X$ and $Y$, $X \supseteq
Y$ means that all types in $Y$ are propagated to $X$ at the time of constraint generation, i.e. during analysis. On the other hand, $X
\barrier Y$ means that if $Y$ contains types that are not in $X$, then a
type barrier is required which updates the types in $X$
according to values which are dynamically assigned to the location
$X$ represents (\Section\ref{sec:analysis-barriers}).
Conditional constraints' antecedents are limited to conjunctions and
disjunctions of set membership tests. For an antecendent $A$ and a constraint
$C$, $A \Implies C$ takes on the meaning of $C$ whenever $A$ holds during
propagation. The universal conditional constraint $\forall o \in T \Implies C$
is like the simple conditional constraint, but is always universally
quantified over all object types of a type set $T$.
Constraint propagation can happen both during analysis and at runtime.
Barriers may trigger propagation at runtime, and the set membership
antecedent is checked \emph{during propagation}. This is a radical departure from the
traditional model of generating a constraint graph then immediately solving
that graph.

Rules for the constraint generation function $\mathcal{C}$ are shown in
Figure~\ref{fig:constraint-rules}. On the lefthand column is the expression or
statement to be analyzed, and on the right hand column is the set of constraints
generated. Statically analyzing a function takes the union of
the results from applying $\mathcal{C}$ to every statement in the method.

The \textsc{Undef}, \textsc{Int}, \textsc{Str}, and \textsc{Obj}
rules for literals and the \textsc{Var} rule for variables are
straightforward.

The \textsc{Fun} rule for anonymous function literals is similar to the object
literal rule, but also sets up additional constraints for its argument $x$ and
its body $e$. This rule may be thought of as a read out of $f$'s argument and an
assignment into $f$'s return value. The body of the function, $s$, is not analyzed. Recall that we analyze functions lazily, so the body is not processed until it is about to execute.

The \textsc{Add} rule is complex, as addition in JavaScript is similarly complex. It is
defined for any combination of values, can perform either a numeric addition,
string concatenation, or even function calls if either of its operands is an
object (calling their \code{valueOf} or \code{toString} members, producing a
number or string).

Using unsound modeling lets us cut through this complexity.
Additions in actual programs are typically used to add two numbers
or concatenate a string with something else.
We statically model exactly these cases
and use semantic triggers to monitor the results produced by other
combinations of values, at little runtime cost.
Note that even the integer addition rule we have given is unsound: the
result will be marked as an integer, ignoring the possibility of
overflow.
%When addition of two integers overflows, the result is not
%expressible in 32 bits, and has type \code{number}.
%Integer overflows are very rare, and as described in \Section\ref{sec:example}
%we treat integer additions as producing integers
%and use a semantic trigger to dynamically update the result of
%overflowing additions.

\textsc{Prop} accesses a named property $p$ from the possible objects referred
to by $x$, with the result the union of $\mathit{prop}(o,p)$ for all such
objects.  This rule is complete only in cases where the object referred to by
$x$ (or its prototype) actually has the $p$ property. Accesses on properties
which are not actually part of an object produce \code{undefined}.
Accesses on missing properties are rare,
and yet in many cases we cannot prove that an object
definitely has some property. In such cases we do not dilute the
resulting type sets with \code{undefined}. We instead use a trigger
on execution paths accessing a missing property to update the result type
of the access with \code{undefined}.

\textsc{Index} is similar to \textsc{Prop}, with the added problem that any
property of the object could be accessed.  In JavaScript, \code{x["p"]} is
equivalent to \code{x.p}. If $x$ has the object type $o$, an index operation
can access a potentially infinite number of type sets $\mathit{prop}(o,p)$.
Figuring out exactly which such properties are possible is generally
intractable. We do not model such arbitrary accesses at all, and treat
all index operations as operating on an integer,
 which we collapse into a single type set
$\mathit{index}(o)$.  In full JavaScript, any indexed access which is on a
non-integer property, or is on an integer property which is missing from an
object, must be accounted for with triggers in the same manner as
\textsc{Prop}.

\textsc{A-Var}, \textsc{A-Prop} and \textsc{A-Index} invert the
corresponding read expressions.  These rules are complete, except that
\textsc{A-Index} presumes that an integer property is being accessed.
Again, in full JavaScript, the effects on $\mathit{prop}(o,p)$ resulting from
assignments to a string index \code{x["p"]} on some $x$ with object type $o$
must be accounted for with runtime checks.

\textsc{App} for function applications may be thought of as an assignment into
$f$'s argument and a read out of $f$'s body, or return value. In other words,
it is analogous to \textsc{Fun} with the polarities reversed.

Our analysis is flow-insensitive, so the \textsc{If} rule is simply the union
of the constraints generated by the branches.

\subsection{Type Barriers}
\label{sec:analysis-barriers}

As described in \Section\ref{sec:example}, type barriers are dynamic type checks
inserted to improve analysis precision in the presence
of polymorphic code.
Propagation along an assignment $X = Y$ can be modeled
statically as a subset
constraint $X \supseteq Y$ or dynamically as a barrier constraint
$X \barrier Y$.
It is always safe to use one in place of the other; in \Section\ref{sec:without_barriers}
we show the effect of always using subset constraints in lieu of
barrier constraints.

For a barrier constraint $X \barrier Y$, a type barrier is required whenever
$X \not\supseteq Y$. The barrier dynamically checks that the type of each value
flowing across the assignment is actually in $X$, and updates $X$ whenever
values of a new type are encountered.
Thought of another way, the vanilla subset constraint propagates
all types during analysis. The barrier subset constraint does not propagate
types during analysis but defers with dynamic checks, propagating the types
only if necessary at runtime.

Type barriers are much like dynamic type casts in Java: assignments from a
more general type to a more specific type are possible as long as a
dynamic test occurs for conformance.
However, rather than throw an exception (as in Java) a tripped type barrier will
despecialize the target of the assignment.

The presence or absence of type barriers for a given barrier constraint is not
monotonic with respect to the contents of the type sets in the program.  As
new types are discovered, new type barriers may be required, and existing ones
may become unnecessary.  However, it is always safe to perform the runtime
tests for a given barrier.

In the constraint generation rules in Figure~\ref{fig:constraint-rules} we
present three rules which employ type barriers:
\textsc{Prop}, \textsc{Index}, and \textsc{Fun}. We use barriers on function
argument binding to precisely model polymorphic call sites where
only certain combinations of argument types and callee functions are possible.
Barriers could be used for other types of assignments, such as at return sites, but we do not do so.
Allowing barriers in new places is unlikely to significantly change the total
number of required barriers --- improving precision by adding barriers in one
place can make barriers in another place unnecessary.
%The main cost is the extra compiler complexity required to support new
%kinds of barriers, and we may take such steps in the future.

\subsection{Example Constraints}
\label{sec:example-constraints}

\begin{figure}
\begin{align}
T_{\code{use}} & \supseteq \{\mathit{Use}\}\label{ct:use}\\
T_{\code{a}'} & \barrier \mathit{arg}(\mathit{Use})\label{ct:use-arg}\\
\mathit{ret}(\mathit{Use}) & \supseteq T_{\code{res}}\label{ct:use-ret}\\
T_{\code{a}} & \supseteq \{A\} \label{ct:1}\\
T_{\code{tmp}} & \supseteq \{\mathit{Box}\} \label{ct:2}\\
\forall o \in T_{\code{tmp}} \Implies \mathit{prop}(o, \code{p}) & \supseteq \{\code{int}\} \label{ct:3}\\
\forall o \in T_{\code{a}} \Implies \mathit{index}(o) & \supseteq T_{\code{tmp}} \label{ct:5}\\
\forall o \in T_{\code{use}} \Implies \mathit{arg}(o) & \supseteq T_{\code{a}}\label{ct:6}\\
\forall o \in T_{\code{use}} \Implies T_{\code{use(a)}} & \supseteq \mathit{ret}(o)\label{ct:7}\\
\forall o \in T_{\code{a}'} \Implies T_{\code{tmp2}} & \barrier \mathit{index}(o)\label{ct:8}\\
\forall o \in T_{\code{tmp2}} \Implies T_{\code{v}} & \barrier \mathit{prop}(o, \code{p})\label{ct:9}
\end{align}
\caption{Motivating Example Constraints}
\label{fig:example-constraints}
\end{figure}

The constraint generation rules as presented are not expressive enough to
process the motivating example in Figure~\ref{fig:motivating-example} in full;
we must first desugar the motivating example to look like the simplified
core. In the interest of space, we will instead focus on a few interesting
lines and provide the desugaring where needed. In the following walkthrough we
show how the variable \code{v} on line 8 gets the type \code{int}.

At line 5, the declaration of the \code{use} function needs to be desugared to
assigning an anonymous function to a variable named \code{use}.\footnote{We do
  not desugar the \code{Box} function in the same fashion as it is used as a
  constructor on line 17.} This will match \textsc{Fun}. Let us call the fresh
object type for the function $\mathit{Use}$. We generate (\ref{ct:use}),
(\ref{ct:use-arg}), and (\ref{ct:use-ret}). To avoid confusion with the
variable \code{a} used below, the argument of \code{use} is renamed to
$\code{a}'$.

At line 15, an empty array is created. The core does not handle arrays, but
for the purposes of constraint generation it is enough to treat them as
objects. Thus, this will match \textsc{Obj} and \textsc{A-Var}. Let us call
the fresh object type for this source location $A$. Combining both rules,
we generate (\ref{ct:1}).

At line 17, \code{Box} objects are created. Though the core does not handle
\lstinline{new} constructions, we may desugar
\lstinline{a[i] = new Box(10);} to \code{tmp = \{\}; tmp.p = 10; a[i]
  = tmp}. The first desugared assignment matches \textsc{Obj} and
\textsc{A-Var}. Let us call the fresh object type for this source location
$\mathit{Box}$ (this desugaring is approximate; in practice for \lstinline{new} we assign
object types to the new object according to the called function's prototype).
We can combine the above two rules to generate (\ref{ct:2}).
The second desugared assignment matches \textsc{A-Prop} and
\textsc{Int}. Again, we can combine these two rules to generate the
conditional (\ref{ct:3}).  The third desugared assignment matches
\textsc{A-Index}. We generate the conditional (\ref{ct:5}). At this point we
propagate $\mathit{Box}$ through (\ref{ct:3}) and $\mathit{A}$
through (\ref{ct:5}), as we know those set memberships hold during analysis.

At line 18, there is a call to \code{use}. This matches \textsc{App} and
generates the constraints (\ref{ct:6}) and (\ref{ct:7}). Note that
(\ref{ct:use-arg}) employs a barrier constraint. Barrier constraints
restrict propagation of types to runtime, so $T_{\code{a}}$
\emph{does not} propagate to $T_{\code{a}'}$ even though we know statically
$\mathit{Use} \in T_{\code{use}}$. And at the current time, before \code{use}
is actually called, $T_{\code{a}'} \not\supseteq T_{\code{a}}$, which means we
need to emit a dynamic check, or type barrier, that continues the propagation
should new types be observed during runtime.

Until \code{main} is executed to the point where \code{use} is called, no
further analysis is done. That is, we \emph{interleave} constraint generation,
propagation, and code execution. Propagation, due to barrier constraints, can
happen during analysis and at runtime.
Suppose then that \code{main} is executed and it calls \code{use}. First,
the type barrier we inserted at the argument binding for \code{use} is
triggered, and the types of $T_{\code{a}}$ are propagated to
$T_{\code{a}'}$. That is, $T_{\code{a}'} \supseteq \{A\}$.

Line 8 is where we tie together our extant constraints. First it must be
desugared to use a temporary: \lstinline{tmp2 = a$'$[i]; v = tmp2.p}. The
first desugared assignment matches \textsc{Index} and \textsc{A-Var}. We
combine the two to generate (\ref{ct:8}). The second desugared assignment
matches \textsc{Prop} and \textsc{A-Var}, so we generate (\ref{ct:9}). Both
(\ref{ct:8}) and (\ref{ct:9}) emit type barriers, so no propagation occurs
until line 8 executes.
The type barrier required by (\ref{ct:8}) is triggered and propagates
$\mathit{Box}$ to $T_{\code{tmp2}}$. Now that $\mathit{Box} \in
T_{\code{tmp2}}$, the type barrier for (\ref{ct:9}) triggers and propagates
\code{int} from $\mathit{prop}(\mathit{Box}, \code{p})$ to $T_{\code{v}}$.

At this point, as we have observed all possible types of the property access
\code{a$'$[i].p}, no dynamic checks are required by the barrier constraints
in (\ref{ct:8}) and (\ref{ct:9}).
But this removal may
not be permanent. If we analyze new code which adds new types to the type set
$\mathit{prop}(\mathit{Box}, \code{p})$, we will need to re-emit the dynamic
check. For instance, if in the future we were to see \lstinline{new Box("hello!")}
elsewhere in the code, we would need to re-emit the type barrier.

\subsection{Supplemental Analyses}
\label{sec:supplemental-analyses}

%In many cases type information itself is insufficient to generate code
%which performs comparably to a statically-typed language such as Java.
Semantic triggers are generally cheap, but they nevertheless incur a cost.
%Integer addition requires checks for overflow,
%index operations on arrays require checks for holes in the middle of the array,
%and property accesses require determining whether the object has the property
%and the physical location where the property is stored.
These checks should be eliminated in as many cases as possible.
Eliminating such checks requires more detailed analysis information.
Rather than build additional complexity into the type analysis itself,
we use supplemental analyses which leverage type information but do not
modify the set of inferred types.
%The remainder of this section briefly describes our handling of the above
%situations.
We describe the three most important supplemental analyses below, and
our implementation contains several others.

\paragraph{Integer Overflow}

In the execution of a JavaScript program, the overall cost of doing integer
overflow checks is very small.
On kernels which do many additions, however, the cost can become significant.
We have measured overflow check overhead at 10-20\% of total execution
time on microbenchmarks.

Using type information, we normally know statically where integers are being
added. We use two techniques on those sites to remove overflow checks.
First, for simple additions in a loop (mainly loop counters) we try to use
the loop termination condition to compute a range
check which can be hoisted from the loop, a standard technique
which can only be performed for JavaScript with type information available.
Second, integer additions which are used as inputs to bitwise operators
do not need overflow checks, as bitwise operators truncate their inputs to 32
bit integers.

\paragraph{Packed Arrays}

Arrays are usually constructed by writing to their elements in ascending
order, with no gaps; we call these arrays {\it packed}.
Packed arrays do not have holes in the middle, and if an access is statically
known to be on a packed array then only a bounds check is required.
There are a large number of ways packed arrays can be constructed, however,
which makes it difficult to statically prove an array is packed.
Instead, we dynamically detect out-of-order writes on an array,
and mark the type of the array object as possibly not packed.
If an object type has never been marked as not packed, then all objects
with that type are packed arrays.

%When compiling an index operation, if the type set of the accessed object
%contains no object types marked as possibly not packed, then the operation
%must be on a packed array.
%In such cases, the generated code does not need to check for a hole in the
%middle of the array, and only needs to perform a bounds check. In turn, the bounds check can
%often be hoisted from loop bodies in the same manner as integer overflow
%checks.

The packed status of an object type can change dynamically due to out-of-order
writes, possibly invalidating JIT code.
%This forces recompilation in the same way as type changes due to semantic
%triggers and tripped type barriers do.

\paragraph{Definite Properties}
\label{sec:definite-properties}

JavaScript objects are internally laid out as a map from property names
to slots in an array of values.
If a property access can be resolved statically to a particular slot in the
array, then the access is on a {\it definite} property and can be compiled
as a direct lookup. This is comparable to
field accesses in a language with static object layouts,
such as Java or C++.

We identify definite property accesses in three ways.
First, if the property access is on an object with a unique type,
we know the exact JavaScript object being accessed and can use the slot
in its property map.
Second, object literals allocated in the same place have the same type,
and definite properties can be picked up from the order the literal
adds properties.
Third, objects created by calling \code{new} on the same function will have the
same prototype (unless the function's \code{prototype} property is overwritten),
and we analyze the function's body to identify properties it definitely
adds before letting the new object escape.

These techniques are sensitive to properties being deleted or
reconfigured, and if such events happen then JIT code will be invalidated
in the same way as by packed array or type set changes.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
